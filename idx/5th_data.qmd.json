{"title":"언론보도 분석을 통한 편의점 3사 평판 비교분석","markdown":{"yaml":{"title":"언론보도 분석을 통한 편의점 3사 평판 비교분석","subtitle":"2021. 09. 01 ~ 2022. 09. 30.","format":{"html":{"code-fold":true,"code-tools":true}},"editor":"visual","author":"언론홍보학과 4학년 김수진(2018102101)","title-block-style":"default","title-block-banner":"#5C491A","date":"2022. 10. 05."},"headingText":"개요","containsRefs":false,"markdown":"\n\n\n#### 분석주제 및 선정 이유\n\n-   분석 주제 : 언론보도 분석을 통한 편의점 평판 비교 분석\n-   주제 선정 이유 : 최근 들어 커머스 분야가 다양해짐에 따라 대형마트, 중형마트, 온라인 커머스, 편의점 등이 각각의 장단점을 활용하여 경영전략 및 마케팅을 펼치고 있다. 그 중에서도 편의점은 소비자들의 생활반경 근처에 다수 포진해있음에 따라 적극적인 변화를 모색하고 있다. 대표적으로 원소주, 말차 등 유명 브랜드의 상품을 독점 판매하거나 tv프로그램 '편스토랑' 등과 같이 콜라보 프로젝트를 진행하고 있다. 이러한 상황에서 각각의 편의점의 평판을 분석하여 어떠한 차이를 보이고 있는지 살펴보고자 한다.\n\n#### 자료분석 방법\n\n-   자료 유형 : 뉴스 (정치, 사회, 스포츠 뉴스 제외)\n\n-   자료 출처 : 빅카인즈\n\n-   자료 기간 : 2021. 09. 01. \\~ 2022. 09. 30. (약 1년간)\n\n-   자료수집\n\n    1)  GS25\n\n    -   검색어 : ((GS25) OR (지에스25) OR (gs25) OR (지에스이십오))\n    -   총 4416건의 기사\n\n    2)  세븐일레븐\n\n    -   검색어 : ((코리아세븐) OR (Korea Seven Co.) OR ((주)코리아세븐) OR (주식회사 코리아세븐) OR (세븐일레븐))\n    -   총 3520건의 기사\n\n    3)  CU\n\n    -   검색어 : ((CU편의점) OR (CU) OR (CU 편의점))\n    -   총 5241건의 기사\n\n### 자료 수집\n\n#### 패키지 설치\n\n```{r}\n#| label: 패키지 설치\n#| echo: true\n#| warning: false\n#| output: false\n\npackage_list <- c(\"tidyverse\", \"tidytext\", \"readxl\", \"kableExtra\", \n                  \"multilinguer\", \"RcppMeCab\", \"KoNLP\", \"lubridate\", \n                  \"tidylo\", \"stm\", \"reshape2\", \"dplyr\", \"ggplot2\", \n                  \"stringr\", \"rvest\", \"wordcloud\", \"tm\", \"VennDiagram\", \"gt\")\n \n#package_list_installed <- package_list %in% installed.packages()[,\"Package\"]\n# new_pkg <- package_list[!package_list_installed]\n# if(length(new_pkg)) install.packages(new_pkg)\n\nlapply(package_list, require, character.only = TRUE)\n```\n\n#### 데이터셋 수집\n\n```{r}\n#| label: 데이터셋 수집\n#| echo: true\n#| warning: false\n\nGS25_df <- readxl::read_excel(\"GS25_year_data.xlsx\") %>% \n  select(제목, 본문)\n\nseven_df <- readxl::read_excel(\"seveneleven_year_data.xlsx\") %>% \n  select(제목, 본문)\n\nCU_df <- readxl::read_excel(\"CU_year_data.xlsx\") %>% \n  select(제목, 본문)\n```\n\n### 자료분석-총빈도\n\n#### GS25\n\n```{r}\n#| label: 총빈도_GS25\n#| echo: true\n#| warning: false\n\nGS25_df2 <- GS25_df %>% \n  distinct(제목, .keep_all = T) %>% \n  mutate(ID = factor(row_number())) %>% \n  mutate(label = \"0\") %>%\n  unite(제목, 본문, col = \"text\", sep = \" \") %>% \n  mutate(text = str_squish(text))\n\nGS25_tk <- GS25_df2 %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F) %>%\n  count(word, sort = T)\n\nGS25_tk <- \nGS25_tk %>% \n  filter(!word %in% c(\"gs\", \"gs25\", \"리테일\", \"기자\", \"편의점\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\")) %>%\n  filter(str_length(word) > 1) %>%\n  slice_max(n, n = 15) %>% \n  mutate(word = reorder(word, n))\n\nGS25_tk %>%\n  ggplot(aes(word, n)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"GS25 총빈도\")\n```\n\n#### 세븐일레븐\n\n```{r}\n#| label: 총빈도_세븐일레븐\n#| echo: true\n#| warning: false\n\nseven_df2 <- seven_df %>% \n  distinct(제목, .keep_all = T) %>% \n  mutate(ID = factor(row_number())) %>% \n  mutate(label = \"0\") %>%\n  unite(제목, 본문, col = \"text\", sep = \" \") %>% \n  mutate(text = str_squish(text))\n\nseven_tk <- seven_df2 %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F) %>%\n  count(word, sort = T)\n\nseven_tk <- \nseven_tk %>% \n  filter(!word %in% c(\"세븐일레븐\", \"기자\", \"편의점\", \"롯데\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\")) %>%\n  filter(str_length(word) > 1) %>%\n  slice_max(n, n = 15) %>% \n  mutate(word = reorder(word, n))\n\nseven_tk %>%\n  ggplot(aes(word, n)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"세븐일레븐 총빈도\")\n\n```\n\n#### CU\n\n```{r}\n#| label: 총빈도_CU\n#| echo: true\n#| warning: false\n\nCU_df2 <- CU_df %>% \n  distinct(제목, .keep_all = T) %>% \n  mutate(ID = factor(row_number())) %>% \n  mutate(label = \"0\") %>%\n  unite(제목, 본문, col = \"text\", sep = \" \") %>% \n  mutate(text = str_squish(text))\n\nCU_tk <- CU_df2 %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F) %>%\n  count(word, sort = T)\n\nCU_tk <- \nCU_tk %>% \n  filter(!word %in% c(\"cu\", \"기자\", \"편의점\", \"리테일\", \"bgf\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\")) %>%\n  filter(str_length(word) > 1) %>%\n  slice_max(n, n = 15) %>% \n  mutate(word = reorder(word, n))\n\nCU_tk %>% \n  ggplot(aes(word, n)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"CU 총빈도\")\n\n```\n\n#### 분석\n\n-   편의점 3사에서 중복으로 나타나는 단어, '키트'는 코로나 상황으로 인한 '코로나 자가진단키트' 판매와 연관되어 있음을 알 수 있음.\n-   편의점 3사에서 '소주', '맥주', '와인' 등 주류 관련 단어 반복적으로 나타남.\n\n### 자료분석-상대빈도\n\n#### GS25, 세븐일레븐\n\n```{r}\n#| label: 상대빈도_세팅1\n#| echo: true\n#| warning: false\n\nweighted_log_odds_df1 <-\n  bind_rows(GS25_tk, seven_tk, .id = \"party\") %>% \n  bind_log_odds(set = party,\n                feature = word, \n                n = n) %>% \n  arrange(-log_odds_weighted)\n```\n\n```{r}\n#| label: 상대빈도_GS25, 세븐일레븐\n#| echo: true\n#| warning: false\n\nlibrary(gt)\nlibrary(dplyr)\n\nGS25.seven_df <- bind_cols(\n  weighted_log_odds_df1 %>%   \n  group_by(party = ifelse(party == 1, \"GS25\", \"세븐일레븐\")) %>% \n  arrange(party) %>% \n  select(-party) %>%\n  head(15),\n  \n  weighted_log_odds_df1 %>%   \n  group_by(party = ifelse(party == 1, \"GS25\", \"세븐일레븐\")) %>% \n  arrange(desc(party)) %>% \n  select(-party) %>%\n  head(15) \n  ) \n\nGS25.seven_df <- GS25.seven_df[-c(1,5)]\n\nGS25.seven_df %>%\n  gt() %>% tab_header(\n  \"상대적으로 많이 사용한 단어\"\n  ) %>% tab_spanner(\n    label = \"GS25 기준\",\n    columns = 1:3\n  ) %>% tab_spanner(\n    label = \"세븐일레븐 기준\",\n    columns = 4:6\n  ) %>% cols_label(\n    word...2 = \"명사\",\n    n...3 = \"빈도\",\n    log_odds_weighted...4 = \"가중상대빈도\",\n    word...6 = \"명사\",\n    n...7 = \"빈도\",\n    log_odds_weighted...8 = \"가중상대빈도\"\n  ) %>% fmt_number(\n    columns = starts_with(\"log\"), \n    decimals = 2\n  )\n\n\n```\n\n-   주류와 관련하여 GS25는 '소주', '맥주'가, 세븐일레븐은 '와인'이 상대적으로 빈도가 나타남.\n-   GS25의 경우, CU 언급이 많은 것으로 보아 직접적인 비교대상임을 알 수 있음.\n\n#### GS25, CU\n\n```{r}\n#| label: 상대빈도_세팅2\n#| echo: true\n#| warning: false\n\nweighted_log_odds_df2 <-\n  bind_rows(GS25_tk, CU_tk, .id = \"party\") %>% \n  bind_log_odds(set = party,\n                feature = word, \n                n = n) %>% \n  arrange(-log_odds_weighted)\n```\n\n```{r}\n#| label: 상대빈도_GS25, CU\n#| echo: true\n#| warning: false\n\nlibrary(gt)\nlibrary(dplyr)\n\nGS25.CU_df <- bind_cols(\n  weighted_log_odds_df2 %>%   \n  group_by(party = ifelse(party == 1, \"GS25\", \"CU\")) %>% \n  arrange(party) %>% \n  select(-party) %>%\n  head(15),\n  \n  weighted_log_odds_df2 %>%   \n  group_by(party = ifelse(party == 1, \"GS25\", \"CU\")) %>% \n  arrange(desc(party)) %>% \n  select(-party) %>%\n  head(15) \n  ) \n\nGS25.CU_df <- GS25.CU_df[-c(1,5)]\n\nGS25.CU_df %>%\n  gt() %>% tab_header(\n  \"상대적으로 많이 사용한 단어\"\n  ) %>% tab_spanner(\n    label = \"GS25 기준\",\n    columns = 1:3\n  ) %>% tab_spanner(\n    label = \"CU 기준\",\n    columns = 4:6\n  ) %>% cols_label(\n    word...2 = \"명사\",\n    n...3 = \"빈도\",\n    log_odds_weighted...4 = \"가중상대빈도\",\n    word...6 = \"명사\",\n    n...7 = \"빈도\",\n    log_odds_weighted...8 = \"가중상대빈도\"\n  ) %>% fmt_number(\n    columns = starts_with(\"log\"), \n    decimals = 2\n  )\n\n\n```\n\n-   주류와 관련하여 GS25는 '맥주'가, CU는 '소주'가 상대적으로 빈도가 높게 나타남. 1개월 정보량에서는 GS25의 '소주' 단어빈도가 앞도적으로 높았으나 1년 정보량을 기준으로 하였을 때는 다른 양상을 보이고 있음을 확인함.\n\n#### 세븐일레븐, CU\n\n```{r}\n#| label: 상대빈도_세팅3\n#| echo: true\n#| warning: false\n\nweighted_log_odds_df3 <-\n  bind_rows(seven_tk, CU_tk, .id = \"party\") %>% \n  bind_log_odds(set = party,\n                feature = word, \n                n = n) %>% \n  arrange(-log_odds_weighted)\n```\n\n```{r}\n#| label: 상대빈도_세븐일레븐, CU\n#| echo: true\n#| warning: false\n\nlibrary(gt)\nlibrary(dplyr)\n\nseven.CU_df <- bind_cols(\n  weighted_log_odds_df3 %>%   \n  group_by(party = ifelse(party == 1, \"세븐일레븐\", \"CU\")) %>% \n  arrange(party) %>% \n  select(-party) %>%\n  head(15),\n  \n  weighted_log_odds_df2 %>%   \n  group_by(party = ifelse(party == 1, \"세븐일레븐\", \"CU\")) %>% \n  arrange(desc(party)) %>% \n  select(-party) %>%\n  head(15) \n  ) \n\nseven.CU_df <- seven.CU_df[-c(1,5)]\n\nseven.CU_df %>%\n  gt() %>% tab_header(\n  \"상대적으로 많이 사용한 단어\"\n  ) %>% tab_spanner(\n    label = \"세븐일레븐 기준\",\n    columns = 1:3\n  ) %>% tab_spanner(\n    label = \"CU 기준\",\n    columns = 4:6\n  ) %>% cols_label(\n    word...2 = \"명사\",\n    n...3 = \"빈도\",\n    log_odds_weighted...4 = \"가중상대빈도\",\n    word...6 = \"명사\",\n    n...7 = \"빈도\",\n    log_odds_weighted...8 = \"가중상대빈도\"\n  ) %>% fmt_number(\n    columns = starts_with(\"log\"), \n    decimals = 2\n  )\n\n\n```\n\n-   주류와 관련하여 세븐일레븐은 '맥주'가, CU는 '소주'가 상대적으로 빈도가 높게 나타남.\n\n### 감정분석\n\n#### 사전 데이터 프레임 만들기\n\n```{r}\n#| label: 감정분석_사전 데이터 프레임1\n#| echo: true\n#| warning: false\n\n# pkg_v <- c(\"tidyverse\", \"tidytext\", \"epubr\", \"RcppMeCab\", \"KoNLP\" )\n# lapply(pkg_v, require, ch = T)\n\n# url_v <- \"https://github.com/park1200656/KnuSentiLex/archive/refs/heads/master.zip\"\n# dest_v <- \"data/knusenti.zip\"\n# download.file(url = url_v, destfile = dest_v, mode = \"wb\")\n\n# unzip(\"knusenti.zip\", exdir=outPath)\n```\n\n```{r}\n#| label: 감정분석_사전 데이터 프레임2\n#| echo: true\n#| warning: false\n\nsenti_name_v <- list.files(\"data/knusenti/KnuSentiLex-master/.\")[9]\nsenti_dic_df <- read_tsv(str_c(\"data/knusenti/KnuSentiLex-master/\", senti_name_v), col_names = F)\nsenti_dic_df <- senti_dic_df %>% rename(word = X1, sScore = X2)\nknu_dic_df <- senti_dic_df %>% \n  filter(!is.na(sScore))\n```\n\n#### GS25\n\n```{r}\n#| label: 감정분석_GS25\n#| echo: true\n#| warning: false\n\nGS25_senti_df <- GS25_df2 %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  count(word, sScore, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  mutate(word = reorder(word, n)) %>% \n  slice_head(n = 20)\n\nGS25_senti_df %>% \n  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +\n    labs(title = \"GS25 감정빈도 분석\")\n```\n\n-   GS25 긍정 이미지 : '할인', '이벤트', '혜택' (할인 위주)\n-   GS25 부정 이미지 : '부담', '화재' 단어의 경우 부정적인 단어를 활용하여 마케팅을 하면서 나타남. '편의점 택배 부담없이 GS25, 반값택배', '화재 시, GS25 소화기 제공' 문구 활용을 볼 수 있음. '피해'의 경우, '국내 최초 가맹점 사기 피해 보상 보험 지원'과 '남혐 논란, GS25피해 CU로'라는 내용으로 살펴볼 수 있음.\n\n#### 세븐일레븐\n\n```{r}\n#| label: 감정분석_세븐일레븐\n#| echo: true\n#| warning: false\n\nseven_senti_df <- seven_df2 %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  count(word, sScore, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  mutate(word = reorder(word, n)) %>% \n  slice_head(n = 20)\n\nseven_senti_df %>% \n  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +\n    labs(title = \"세븐일레븐 감정빈도 분석\")\n```\n\n-   세븐일레븐 긍정 이미지 : '할인', '혜택', '이벤트' (할인 중심)\n-   세븐일레븐 부정 이미지 : '부담'의 경우 '학생 맞춤형 도시락...부담을 낮췄다', '식사 후 커피 부담되는데..반값커피' 등 물가 부담과 대비되는 제품을 출시하면서 단어 빈도가 높아짐. '피해'는 지난 9월에 발생한 태풍 피해를 의미하고 있음.\n\n#### CU\n\n```{r}\n#| label: 감정분석_CU\n#| echo: true\n#| warning: false\n\nCU_senti_df <- CU_df2 %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  count(word, sScore, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  mutate(word = reorder(word, n)) %>% \n  slice_head(n = 20)\n\nCU_senti_df %>% \n  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +\n    labs(title = \"CU 감정빈도 분석\")\n```\n\n-   CU 긍정 이미지 : '할인', '이벤트', '혜택' (할인 중심)\n-   CU 부정 이미지 : '부담'의 경우, '부담없이'라는 카피를 반복적으로 사용함으로써 빈도가 높게 나타남.\n\n### 감정분석 - 긍정어, 부정어\n\n#### GS25\n\n```{r}\n#| label: 긍정어, 부정어_GS25\n#| echo: true\n#| warning: false\n\nGS25_df2 %>% \n  unnest_tokens(word, text) %>% \n  left_join(knu_dic_df) %>% \n  mutate(sScore = ifelse(sScore >= 1, \"긍정\",\n                         ifelse(sScore <= -1, \"부정\", \"중립\"))) %>% \n  count(sScore)\n\nGS25_df2 %>%   \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>%\n  mutate(label = ifelse(sScore > 0, \"1\", ifelse(sScore < 0, \"0\", \"2\"))) %>%\n  filter(label != \"중립\") %>%\n  count(word, emotion, label, sort = T) %>%\n  filter(str_length(word) > 1) %>%\n  group_by(label = ifelse(label > 0, \"긍정\", \"부정\")) %>%\n  slice_head(n = 15) %>%\n  ggplot(aes(x = n,\n             y = reorder(word, n), fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\") +\n  labs(title = \"GS25 긍정어 부정어\")\n```\n\n#### 세븐일레븐\n\n```{r}\n#| label: 긍정어, 부정어_세븐일레븐\n#| echo: true\n#| warning: false\n\nseven_df2 %>% \n  unnest_tokens(word, text) %>% \n  left_join(knu_dic_df) %>% \n  mutate(sScore = ifelse(sScore >= 1, \"긍정\",\n                         ifelse(sScore <= -1, \"부정\", \"중립\"))) %>% \n  count(sScore)\n\nseven_df2 %>%   \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>%\n  mutate(label = ifelse(sScore > 0, \"1\", ifelse(sScore < 0, \"0\", \"2\"))) %>%\n  filter(label != \"중립\") %>%\n  count(word, emotion, label, sort = T) %>%\n  filter(str_length(word) > 1) %>%\n  group_by(label = ifelse(label > 0, \"긍정\", \"부정\")) %>%\n  slice_head(n = 15) %>%\n  ggplot(aes(x = n,\n             y = reorder(word, n), fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\") +\n  labs(title = \"세븐일레븐 긍정어 부정어\")\n```\n\n#### CU\n\n```{r}\n#| label: 긍정어, 부정어_CU\n#| echo: true\n#| warning: false\n\nCU_df2 %>% \n  unnest_tokens(word, text) %>% \n  left_join(knu_dic_df) %>% \n  mutate(sScore = ifelse(sScore >= 1, \"긍정\",\n                         ifelse(sScore <= -1, \"부정\", \"중립\"))) %>% \n  count(sScore)\n\nCU_df2 %>%   \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>%\n  mutate(label = ifelse(sScore > 0, \"1\", ifelse(sScore < 0, \"0\", \"2\"))) %>%\n  filter(label != \"중립\") %>%\n  count(word, emotion, label, sort = T) %>%\n  filter(str_length(word) > 1) %>%\n  group_by(label = ifelse(label > 0, \"긍정\", \"부정\")) %>%\n  slice_head(n = 15) %>%\n  ggplot(aes(x = n,\n             y = reorder(word, n), fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\") +\n  labs(title = \"CU 긍정어 부정어\")\n```\n\n### 토픽모델링\n\n#### GS25\n\n```{r}\n#| label: 토픽모델링_GS25\n#| echo: true\n#| warning: false\n\nGS25_topic_tk <- GS25_df2 %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F)\n\nGS25_topic_tk <- \nGS25_topic_tk %>% \n  filter(!word %in% c(\"gs\", \"gs25\", \"리테일\", \"기자\", \"편의점\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nGS25_combined_df <-\n  GS25_topic_tk %>%\n  group_by(ID) %>%\n  summarise(text2 = str_flatten(word, \" \")) %>%\n  ungroup() %>% \n  inner_join(GS25_df2, by = \"ID\")\n\nlibrary(stm)\nlibrary(tm)\n\nprocessed <- \n  GS25_df2 %>% textProcessor(\n    documents = GS25_combined_df$text2,\n    metadata = .,\n    wordLengths = c(2, Inf)\n    )\n\nout <-\n  prepDocuments(processed$documents,\n                processed$vocab,\n                processed$meta, \n                lower.thresh = 0)\ndocs <- out$documents\nvocab <- out$vocab\nmeta <- out$meta\ntopicN <- c(3, 10)\n#storage <- searchK(out$documents, out$vocab, K = topicN)\n\nGS25_stm_fit <-\n  stm(\n    documents = docs,\n    vocab = vocab,\n    K = 6,\n    data = meta,\n    max.em.its = 75,\n    init.type = \"Spectral\",\n    seed = 25,\n    verbose = F\n  )\n\n#labelTopics(GS25_stm_fit)\n\nGS25_topic_name <- tibble(topic = 1:6,\n                     name = c(\"1. 사업 경영\",\n                              \"2. 점포 운영\",\n                              \"3. 경쟁\",\n                              \"4. 판매, 출시\",\n                              \"5. 배송, 온라인\",\n                              \"6. 프로모션\"))\n\nGS25_td_beta <- GS25_stm_fit %>% tidy(matrix = 'beta') \nGS25_topic_name <- GS25_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 7) %>% \n  left_join(GS25_topic_name, by = \"topic\")\n\nGS25_topic_name %>% \n  ggplot(aes(x = beta, \n             y = reorder_within(term, beta, name),  # 각 주제별로 재정렬\n             fill = name)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~name, scales = \"free\") +\n  scale_y_reordered() +                             # 재정렬한 y축의 값 설정\n  labs(x = expression(\"단어 확률분포: \"~beta), y = NULL,\n       title = \"GS25 주제별 단어 확률 분포\",\n       subtitle = \"주제별로 다른 단어들로 군집\") +\n  theme(plot.title = element_text(size = 20))\n```\n\n#### 세븐일레븐\n\n```{r}\n#| label: 토픽모델링_세븐일레븐\n#| echo: true\n#| warning: false\n\nseven_topic_tk <- seven_df2 %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F)\n\nseven_topic_tk <- \nseven_topic_tk %>% \n  filter(!word %in% c(\"세븐일레븐\", \"기자\", \"편의점\", \"롯데\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nseven_combined_df <-\n  seven_topic_tk %>%\n  group_by(ID) %>%\n  summarise(text2 = str_flatten(word, \" \")) %>%\n  ungroup() %>% \n  inner_join(seven_df2, by = \"ID\")\n\nlibrary(stm)\nlibrary(tm)\n\nprocessed <- \n  seven_df2 %>% textProcessor(\n    documents = seven_combined_df$text2,\n    metadata = .,\n    wordLengths = c(2, Inf)\n    )\n\nout <-\n  prepDocuments(processed$documents,\n                processed$vocab,\n                processed$meta, \n                lower.thresh = 0)\ndocs <- out$documents\nvocab <- out$vocab\nmeta <- out$meta\ntopicN <- c(3, 10)\n#storage <- searchK(out$documents, out$vocab, K = topicN)\n\nseven_stm_fit <-\n  stm(\n    documents = docs,\n    vocab = vocab,\n    K = 6,\n    data = meta,\n    max.em.its = 75,\n    init.type = \"Spectral\",\n    seed = 25,\n    verbose = F\n  )\n\n#labelTopics(seven_stm_fit)\n\nseven_topic_name <- tibble(topic = 1:6,\n                     name = c(\"1. 신제품\",\n                              \"2. 프로모션\",\n                              \"3. 콜라보레이션\",\n                              \"4. 코로나 상황\",\n                              \"5. 매출\",\n                              \"6. 배달, 모빌리티\"))\n\nseven_td_beta <- seven_stm_fit %>% tidy(matrix = 'beta') \nseven_topic_name <- seven_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 7) %>% \n  left_join(seven_topic_name, by = \"topic\")\n\nseven_topic_name %>% \n  ggplot(aes(x = beta, \n             y = reorder_within(term, beta, name),  # 각 주제별로 재정렬\n             fill = name)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~name, scales = \"free\") +\n  scale_y_reordered() +                             # 재정렬한 y축의 값 설정\n  labs(x = expression(\"단어 확률분포: \"~beta), y = NULL,\n       title = \"세븐일레븐 주제별 단어 확률 분포\",\n       subtitle = \"주제별로 다른 단어들로 군집\") +\n  theme(plot.title = element_text(size = 20))\n```\n\n#### CU\n\n```{r}\n#| label: 토픽모델링_CU\n#| echo: true\n#| warning: false\n\nCU_topic_tk <- CU_df2 %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F)\n\nCU_topic_tk <- \nCU_topic_tk %>% \n  filter(!word %in% c(\"cu\", \"기자\", \"편의점\", \"리테일\", \"bgf\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nCU_combined_df <-\n  CU_topic_tk %>%\n  group_by(ID) %>%\n  summarise(text2 = str_flatten(word, \" \")) %>%\n  ungroup() %>% \n  inner_join(CU_df2, by = \"ID\")\n\nlibrary(stm)\nlibrary(tm)\n\nprocessed <- \n  CU_df2 %>% textProcessor(\n    documents = CU_combined_df$text2,\n    metadata = .,\n    wordLengths = c(2, Inf)\n    )\n\nout <-\n  prepDocuments(processed$documents,\n                processed$vocab,\n                processed$meta, \n                lower.thresh = 0)\ndocs <- out$documents\nvocab <- out$vocab\nmeta <- out$meta\ntopicN <- c(3, 10)\n#storage <- searchK(out$documents, out$vocab, K = topicN)\n\nCU_stm_fit <-\n  stm(\n    documents = docs,\n    vocab = vocab,\n    K = 6,\n    data = meta,\n    max.em.its = 75,\n    init.type = \"Spectral\",\n    seed = 25,\n    verbose = F\n  )\n\n#labelTopics(CU_stm_fit)\n\nCU_topic_name <- tibble(topic = 1:6,\n                     name = c(\"1. 제휴, 운영\",\n                              \"2. 경쟁\",\n                              \"3. 코로나 상황\",\n                              \"4. 매출, 운영\",\n                              \"5. 출시, 판매\",\n                              \"6. 브랜드 캠페인\"))\n\nCU_td_beta <- CU_stm_fit %>% tidy(matrix = 'beta') \nCU_topic_name <- CU_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 7) %>% \n  left_join(CU_topic_name, by = \"topic\")\n\nCU_topic_name %>% \n  ggplot(aes(x = beta, \n             y = reorder_within(term, beta, name),  # 각 주제별로 재정렬\n             fill = name)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~name, scales = \"free\") +\n  scale_y_reordered() +                             # 재정렬한 y축의 값 설정\n  labs(x = expression(\"단어 확률분포: \"~beta), y = NULL,\n       title = \"CU 주제별 단어 확률 분포\",\n       subtitle = \"주제별로 다른 단어들로 군집\") +\n  theme(plot.title = element_text(size = 20))\n```\n\n### 관련보도 상위 주제어\n\n#### GS25\n\n```{r}\n#| label: 관련보도 상위 주제어_GS25\n#| echo: true\n#| warning: false\n\nGS25_td_gamma <- GS25_stm_fit %>% tidy(matrix = \"gamma\") \nGS25_top_terms <- \nGS25_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 5) %>% \n  select(topic, term) %>% \n  summarise(terms = str_flatten(term, collapse = \", \")) \n\nGS25_gamma_terms <- \nGS25_td_gamma %>% \n  group_by(topic) %>% \n  summarise(gamma = mean(gamma)) %>% \n  left_join(GS25_top_terms, by = 'topic') %>% \n  left_join(GS25_topic_name, by = 'topic')\n  \nGS25_gamma_terms %>% \n  \n  ggplot(aes(x = gamma, y = reorder(name, gamma), fill = name)) +\n  geom_col(show.legend = F) +\n  geom_text(aes(label = round(gamma, 2)), # 소수점 2자리 \n            hjust = 1.15) +                # 라벨을 막대도표 안쪽으로 이동\n  geom_text(aes(label = terms), \n            hjust = -0.05) +              # 단어를 막대도표 바깥으로 이동\n  #scale_x_continuous(expand = c(0, 0),    # x축 막대 위치를 Y축쪽으로 조정\n  #                   limit = c(0, 1)) +   # x축 범위 설정\n  labs(x = expression(\"문서 확률분포\"~(gamma)), y = NULL,\n       title = \"GS25 관련보도 상위 주제어\",\n       subtitle = \"주제별로 기여도가 높은 단어 중심\") +\n  theme(plot.title = element_text(size = 20))\n```\n\n-   '사업경영'과 관련하여 GS25가 쿠캣마켓과 요기요를 인수한 점을 확인함. 동시에 세븐일레븐이 미니스톱을 인수한 내용도 함께 살펴볼 수 있음.\n-   소주, 맥주, 코로나진단키트가 GS25의 주요 판매품인 것을 확인할 수 있음.\n-   은행, 택배의 역할들을 가져오려는 모습들이 보이고, 운영에 있어 컨테이너 무인점포를 운영한 것이 큰 이슈가 됨.\n\n#### 세븐일레븐\n\n```{r}\n#| label: 관련보도 상위 주제어_세븐일레븐\n#| echo: true\n#| warning: false\n\nseven_td_gamma <- seven_stm_fit %>% tidy(matrix = \"gamma\") \nseven_top_terms <- \nseven_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 5) %>% \n  select(topic, term) %>% \n  summarise(terms = str_flatten(term, collapse = \", \")) \n\nseven_gamma_terms <- \nseven_td_gamma %>% \n  group_by(topic) %>% \n  summarise(gamma = mean(gamma)) %>% \n  left_join(seven_top_terms, by = 'topic') %>% \n  left_join(seven_topic_name, by = 'topic')\n\nseven_gamma_terms %>% \n  \n  ggplot(aes(x = gamma, y = reorder(name, gamma), fill = name)) +\n  geom_col(show.legend = F) +\n  geom_text(aes(label = round(gamma, 2)), # 소수점 2자리 \n            hjust = 1.15) +                # 라벨을 막대도표 안쪽으로 이동\n  geom_text(aes(label = terms), \n            hjust = -0.05) +              # 단어를 막대도표 바깥으로 이동\n  #scale_x_continuous(expand = c(0, 0),    # x축 막대 위치를 Y축쪽으로 조정\n  #                   limit = c(0, 1)) +   # x축 범위 설정\n  labs(x = expression(\"문서 확률분포\"~(gamma)), y = NULL,\n       title = \"세븐일레븐 관련보도 상위 주제어\",\n       subtitle = \"주제별로 기여도가 높은 단어 중심\") +\n  theme(plot.title = element_text(size = 20))\n```\n\n-   와인이 세븐일레븐의 매출에 큰 영향을 미치고 있음을 짐작할 수 있음.\n-   다른 편의점과 달리 배달, 로봇, 배송 등의 키워드를 통해 모빌리티에 큰 관심을 살펴볼 수 있음.\n-   포켓몬 캐릭터를 활용한 콜라보레이션이 큰 이슈가 되었음.\n\n#### CU\n\n```{r}\n#| label: 관련보도 상위 주제어_CU\n#| echo: true\n#| warning: false\n\nCU_td_gamma <- CU_stm_fit %>% tidy(matrix = \"gamma\") \nCU_top_terms <- \nCU_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 5) %>% \n  select(topic, term) %>% \n  summarise(terms = str_flatten(term, collapse = \", \")) \n\nCU_gamma_terms <- \nCU_td_gamma %>% \n  group_by(topic) %>% \n  summarise(gamma = mean(gamma)) %>% \n  left_join(CU_top_terms, by = 'topic') %>% \n  left_join(CU_topic_name, by = 'topic')\n\nCU_gamma_terms %>% \n  \n  ggplot(aes(x = gamma, y = reorder(name, gamma), fill = name)) +\n  geom_col(show.legend = F) +\n  geom_text(aes(label = round(gamma, 2)), # 소수점 2자리 \n            hjust = 1.15) +                # 라벨을 막대도표 안쪽으로 이동\n  geom_text(aes(label = terms), \n            hjust = -0.05) +              # 단어를 막대도표 바깥으로 이동\n  #scale_x_continuous(expand = c(0, 0),    # x축 막대 위치를 Y축쪽으로 조정\n  #                   limit = c(0, 1)) +   # x축 범위 설정\n  labs(x = expression(\"문서 확률분포\"~(gamma)), y = NULL,\n       title = \"CU 관련보도 상위 주제어\",\n       subtitle = \"주제별로 기여도가 높은 단어 중심\") +\n  theme(plot.title = element_text(size = 20))\n```\n\n-   다른 편의점과 달리, 신제품 출시보다는 브랜드 캠페인에 많은 노력을 기울임.\n-   마케팅에 있어서도 특정 브랜드, 캐릭터와의 콜라보레이션보다는 카드 제휴, 할인 행사 등 자체적으로 진행하는 행사가 주를 이룸.\n\n### 결론\n\n#### 평판 비교\n\n-   \n\n    공통점\n\n    :   편의점 3사가 공통적으로 '코로나 자가진단키트', '주류'와 관련된 단어들이 다수 언급되었습니다. 그 배경을 살펴보면 다음과 같습니다. 코로나 상황에서 자가진단키트가 판매가능해지자 편의점들은 발빠르게 판매를 시작하였고, 동네를 기점으로 점포들이 많이 형성되어 있어서 소비자들이 쉽게 접근할 수 있었습니다. 더불어 편의점의 주요 판매제품이 주류임을 인지하고 이와 관련하여 단독판매, 프리미엄 매장, 제품 확대 등의 노력들이 진행하였습니다.\n\n-   GS25 : 스타트업 인수를 통해 사업 고도화를 진행하고, 은행 및 택배 등 다른 산업군의 역할들을 편의점에 적용하려는 시도들이 많이 언급되었습니다. 즉, '사업확장'을 중심으로 평판을 형성하고 있음을 확인하였습니다.\n\n-   세븐일레븐 : 주류 중 와인 상품 다양화를 진행하고, 포켓몬 캐릭터를 활용하여 제품을 판매하고 팝업스토어를 운영하였습니다. 즉, '제품 브랜딩'을 중심으로 평판을 형성하고 있음을 확인하였습니다. 더불어 모빌리티 사업의 확장과 관련하여서도 높은 빈도로 언급되었습니다.\n\n-   CU : 카드 제휴 및 할인 행사 등의 프로모션을 중심으로 마케팅을 진행하고, 메타버스와 결합하거나 친환경을 주제로 회사 브랜드를 형성하는데 집중하고 있습니다. 즉, '회사 브랜드 캠페인'을 중심으로 평판을 형성하고 있음을 확인하였습니다.\n\n#### 평판 전략 방향\n\n-   GS25는 마을 반경 안에서 자주 방문하는 곳들을 통합하려는 시도와 함께, 화재시 소화기를 무상 제공하는 등 일상과 밀접한 캠페인을 진행하였습니다. 즉, '동네 주요 기점'으로 성장하려는 노력을 기사를 통해 잘 전달되었습니다.\n-   세븐일레븐은 제품에 있어 타사와 차별화를 가지려고 노력하였습니다. 이는 곧 다른 편의점이 아닌 해당 편의점을 방문해야만 하는 이유를 제시해줌으로 좋은 전략이라고 볼 수 있습니다. 이러한 전략을 기사를 통해 더 견고히 하려는 모습이 보였습니다.\n-   CU는 기능적인 프로모션과 회사 브랜딩에 집중하였지만 각각의 요소들이 일관된 메시지(혹은 컨셉)를 보여주고 있지는 않습니다. 경쟁력을 가지기 위해서는 메시지를 분명히 하고 프로모션, 사업확장, 캠페인 등에 있어 유기적으로 일관된 컨셉을 보여주어야 할 것입니다. 그래야만 회사에서 효과적으로 평판 관리를 할 수 있을 뿐만 아니라 장기적으로 충성고객을 형성할 수 있을 것입니다.\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"5th_data.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.0.36","bibliography":["references.bib"],"theme":"flatly","title":"언론보도 분석을 통한 편의점 3사 평판 비교분석","subtitle":"2021. 09. 01 ~ 2022. 09. 30.","editor":"visual","author":"언론홍보학과 4학년 김수진(2018102101)","title-block-style":"default","title-block-banner":"#5C491A","date":"2022. 10. 05."},"extensions":{"book":{"multiFile":true}}}}}