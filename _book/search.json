[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "편의점 브랜드 GS25: 평판 관리 방향 제안",
    "section": "",
    "text": "0.0.2 연도별 편의점 트렌드 기준 GS25 언론보도 분석\n\n0.0.2.1 감정분석 (긍정어, 부정어)\n \n \n\nGS25의 핵심 키워드 : 편의점과 관련된 키워드와 비교하였을 때, ‘인기’, ‘할인’, ‘이벤트’, ‘혜택’ 등의 커머스 성격과 관련된 키워드들은 유사하게 나타남. 하지만 ‘맛집’, ’최저가’는 GS25가 두드러지게 보이는 키워드로서 전체적인 편의점 트렌드에서 핵심 키워드를 선점하고 있음을 예상함.\nGS25의 남성혐오 논란 : 2022년 남성 혐오 논란이 있었는데, 이는 편의점 부정어 2위 ’혐오’와 연결되는 이슈로, GS25가 부정적인 이미지를 얻는데 큰 영향을 미쳤음을 알 수 있음.\nCSR 및 CSV 측면 : GS25는 ‘화재 시, GS25 소화기 제공’, ‘국내 최초 가맹점 사기 피해 보상 보험 지원’ 등 편의점 소비와 직간접적인 마케팅을 펼쳐왔음. 2022년 편의점 부정어 중 ’장애인’의 경우, 장애인 직업 훈련과 관련하여 일자리 창출 측면에서 긍정적인 의미와 장애인 편의시설이 갖추어질 필요가 있다는 장애인 이동권 측면에서 부정적인 의미를 함께 내포하고 있음. 이와 관련하여 2021년 GS25 부정어 중 ’장애인’을 살펴보면, ’늘봄스토어’를 통해 장애인 취업 기회를 이전부터 제공해왔음을 알 수 있음. 즉, 사회적인 분위기에 알맞은 CSV를 펼치고 있음을 알 수 있음.\n\n\n\n0.0.2.2 토픽모델링\n \n \n \n \n\n상품 고도화(주류, 도시락) : 2021년, 2022년 모두 편의점 상위주제어에는 맥주, 와인, 상품 등 ‘제품 출시’가 높은 상위 주제어로 언급됨. 이에 대해 GS25는 ’주류 판매’, ‘도시락 상품’ 군집에서 알 수 있듯이 특정 제품 카테고리의 고도화를 진행함. 특히 주류는 편의점 트렌드와 부합하여 시너지를 내고 있음.\n배달 및 택배 서비스 : 2021년 편의점 ‘유통’ 군집에서 ‘gs’, ‘배달’ 등의 키워드가 모여있음. 그리고 2021년 GS25 ‘배달서비스’ 군집에서 ‘배송’, ‘배달’ 등의 키워드가 모여있음. 즉, 2021년에 ‘배달 서비스’와 관련하여 GS25가 선도하고 있음을 예상해볼 수 있음. 하지만 2022년 GS25 ’배달 서비스’ 군집이 상위에 형성되지 않음을 통해 GS25가 앞으로 계속해서 선점하고 싶은 이미지가 아님을 알 수 있음.\n결제 방식 : 2021년 편의점 ‘결제방식’ 군집을 살펴보면, ‘카드’, ‘포인트’, ‘결제’ 등의 키워드를 중심으로 결제의 다양화 모습을 살펴볼 수 있음. 이메 발맞추어 2021년 GS25 ‘결제방식’ 군집을 살펴보면, ‘페이’, ‘서비스’ 등으로 앞에 언급한 결제의 다양화를 실천하고 있음. 페이 결제, 택배 선결제를 바탕으로 ’결제 방식’을 개선하였고, 배달 서비스를 시작하였으며, LG유플러스와 협약하여 AI, 빅데이터 솔루션을 도입하고 LG 유플러스 멤버십 대상 구독 서비스를 선보이기도 함.\n점포 운영(지역, 안전, 청소년) : 2021년, 2022년 편의점 ‘점포 운영’ 군집을 살펴보면 ‘지역’, ‘안전’, ‘청소년’ 키워드가 주로 언급됨. 일상생활 반경 내 편의점의 갯수가 증가함에 따라 편의점이 단순 커머스의 기능 뿐만 아니라 ‘지역 기반’, ‘청소년의 높은 접근성’을 가진 ’안전 장소’로 인지되고 있음. 즉, ’동네 거점 기능’이 고도화되었음을 알 수 있음. 토픽모델링에서 나타나지 않았지만, 위에서 제시한 긍정어, 부정어를 살펴보았을 때, GS25가 동네 주요 기점’ 역할로서 장애인 취업 지원, 미아 방지 캠페인, 소화기 제공 등 노력하는 모습들과 연결짓어 생각해볼 수 있음.\n\n\n\n\n0.0.3 결론 : GS25의 평판 관리 방향 제안\n\n결제 방식 : 편의점 트렌드에 맞게 GS25 역시 적극적으로 결제 방식의 다양화를 실천하고 있음. 다만, 이와 관련하여 CU가 카드 회사와의 제휴 및 할인 혜택을 통해 ‘결제 방식의 편리함’ 키워드를 선점하고 있음.\n콜라보레이션 : GS25의 경우, 원소주와 포켓몬 캐릭터 콜라보레이션을 통해 성공적으로 마케팅을 펼침. 다만, 세븐일레븐이 팝업스토어 등을 통해 포켓몬 캐릭터 콜라보레이션을 극대화함으로써 편의점 브랜드 사이에서 상대적인 이점을 갖지는 못했다고 판단됨.\n동네 거점 기능 : 타브랜드와 뚜렸하게 구별되어 GS25가 독보적으로 가지고 있는 이미지임. 단순 이미지에 머무는 것이 아니라 캠페인, 점포 운영에 있어서도 적극적으로 핵심 컨셉으로 활용됨. 하지만 토픽모델링과 관련 보도 상위 주제어에서 두드러지게 나타나지 않고 있음. 이를 위해서는 캠페인 운영에 있어 관심 및 구전효과를 극대화할 수 있는 마케팅적인 요소를 더해 ’동네 거점 기능’을 중심으로 평판이 형성될 수 있도록 하는 것이 필요함."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "5th_data.html",
    "href": "5th_data.html",
    "title": "1  언론보도 분석을 통한 편의점 3사 평판 비교분석",
    "section": "",
    "text": "1.0.2 자료 수집\n\n1.0.2.1 패키지 설치\n\n\nCode\npackage_list <- c(\"tidyverse\", \"tidytext\", \"readxl\", \"kableExtra\", \n                  \"multilinguer\", \"RcppMeCab\", \"KoNLP\", \"lubridate\", \n                  \"tidylo\", \"stm\", \"reshape2\", \"dplyr\", \"ggplot2\", \n                  \"stringr\", \"rvest\", \"wordcloud\", \"tm\", \"VennDiagram\", \"gt\")\n \n#package_list_installed <- package_list %in% installed.packages()[,\"Package\"]\n# new_pkg <- package_list[!package_list_installed]\n# if(length(new_pkg)) install.packages(new_pkg)\n\nlapply(package_list, require, character.only = TRUE)\n\n\n\n\n1.0.2.2 데이터셋 수집\n\n\nCode\nGS25_df <- readxl::read_excel(\"GS25_year_data.xlsx\") %>% \n  select(제목, 본문)\n\nseven_df <- readxl::read_excel(\"seveneleven_year_data.xlsx\") %>% \n  select(제목, 본문)\n\nCU_df <- readxl::read_excel(\"CU_year_data.xlsx\") %>% \n  select(제목, 본문)\n\n\n\n\n\n1.0.3 자료분석-총빈도\n\n1.0.3.1 GS25\n\n\nCode\nGS25_df2 <- GS25_df %>% \n  distinct(제목, .keep_all = T) %>% \n  mutate(ID = factor(row_number())) %>% \n  mutate(label = \"0\") %>%\n  unite(제목, 본문, col = \"text\", sep = \" \") %>% \n  mutate(text = str_squish(text))\n\nGS25_tk <- GS25_df2 %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F) %>%\n  count(word, sort = T)\n\nGS25_tk <- \nGS25_tk %>% \n  filter(!word %in% c(\"gs\", \"gs25\", \"리테일\", \"기자\", \"편의점\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\")) %>%\n  filter(str_length(word) > 1) %>%\n  slice_max(n, n = 15) %>% \n  mutate(word = reorder(word, n))\n\nGS25_tk %>%\n  ggplot(aes(word, n)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"GS25 총빈도\")\n\n\n\n\n\n\n\n1.0.3.2 세븐일레븐\n\n\nCode\nseven_df2 <- seven_df %>% \n  distinct(제목, .keep_all = T) %>% \n  mutate(ID = factor(row_number())) %>% \n  mutate(label = \"0\") %>%\n  unite(제목, 본문, col = \"text\", sep = \" \") %>% \n  mutate(text = str_squish(text))\n\nseven_tk <- seven_df2 %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F) %>%\n  count(word, sort = T)\n\nseven_tk <- \nseven_tk %>% \n  filter(!word %in% c(\"세븐일레븐\", \"기자\", \"편의점\", \"롯데\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\")) %>%\n  filter(str_length(word) > 1) %>%\n  slice_max(n, n = 15) %>% \n  mutate(word = reorder(word, n))\n\nseven_tk %>%\n  ggplot(aes(word, n)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"세븐일레븐 총빈도\")\n\n\n\n\n\n\n\n1.0.3.3 CU\n\n\nCode\nCU_df2 <- CU_df %>% \n  distinct(제목, .keep_all = T) %>% \n  mutate(ID = factor(row_number())) %>% \n  mutate(label = \"0\") %>%\n  unite(제목, 본문, col = \"text\", sep = \" \") %>% \n  mutate(text = str_squish(text))\n\nCU_tk <- CU_df2 %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F) %>%\n  count(word, sort = T)\n\nCU_tk <- \nCU_tk %>% \n  filter(!word %in% c(\"cu\", \"기자\", \"편의점\", \"리테일\", \"bgf\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\")) %>%\n  filter(str_length(word) > 1) %>%\n  slice_max(n, n = 15) %>% \n  mutate(word = reorder(word, n))\n\nCU_tk %>% \n  ggplot(aes(word, n)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"CU 총빈도\")\n\n\n\n\n\n\n\n1.0.3.4 분석\n\n편의점 3사에서 중복으로 나타나는 단어, ‘키트’는 코로나 상황으로 인한 ’코로나 자가진단키트’ 판매와 연관되어 있음을 알 수 있음.\n편의점 3사에서 ‘소주’, ‘맥주’, ‘와인’ 등 주류 관련 단어 반복적으로 나타남.\n\n\n\n\n1.0.4 자료분석-상대빈도\n\n1.0.4.1 GS25, 세븐일레븐\n\n\nCode\nweighted_log_odds_df1 <-\n  bind_rows(GS25_tk, seven_tk, .id = \"party\") %>% \n  bind_log_odds(set = party,\n                feature = word, \n                n = n) %>% \n  arrange(-log_odds_weighted)\n\n\n\n\nCode\nlibrary(gt)\nlibrary(dplyr)\n\nGS25.seven_df <- bind_cols(\n  weighted_log_odds_df1 %>%   \n  group_by(party = ifelse(party == 1, \"GS25\", \"세븐일레븐\")) %>% \n  arrange(party) %>% \n  select(-party) %>%\n  head(15),\n  \n  weighted_log_odds_df1 %>%   \n  group_by(party = ifelse(party == 1, \"GS25\", \"세븐일레븐\")) %>% \n  arrange(desc(party)) %>% \n  select(-party) %>%\n  head(15) \n  ) \n\nGS25.seven_df <- GS25.seven_df[-c(1,5)]\n\nGS25.seven_df %>%\n  gt() %>% tab_header(\n  \"상대적으로 많이 사용한 단어\"\n  ) %>% tab_spanner(\n    label = \"GS25 기준\",\n    columns = 1:3\n  ) %>% tab_spanner(\n    label = \"세븐일레븐 기준\",\n    columns = 4:6\n  ) %>% cols_label(\n    word...2 = \"명사\",\n    n...3 = \"빈도\",\n    log_odds_weighted...4 = \"가중상대빈도\",\n    word...6 = \"명사\",\n    n...7 = \"빈도\",\n    log_odds_weighted...8 = \"가중상대빈도\"\n  ) %>% fmt_number(\n    columns = starts_with(\"log\"), \n    decimals = 2\n  )\n\n\n\n\n\n\n  \n    \n      상대적으로 많이 사용한 단어\n    \n    \n  \n  \n    \n      \n        GS25 기준\n      \n      \n        세븐일레븐 기준\n      \n    \n    \n      명사\n      빈도\n      가중상대빈도\n      명사\n      빈도\n      가중상대빈도\n    \n  \n  \n    gs25는\n787\n18.36\n배달\n534\n18.05\n    운영\n781\n18.29\n브랜드\n534\n18.05\n    매출\n673\n16.89\n와인\n515\n17.70\n    고객\n647\n16.54\n시장\n474\n16.95\n    점포\n626\n16.25\n들이\n461\n16.70\n    소주\n791\n0.48\n서비스\n770\n3.06\n    맥주\n672\n0.02\n업계\n784\n1.93\n    cu\n719\n−0.33\n키트\n559\n1.40\n    가격\n660\n−0.97\n출시\n941\n1.38\n    상품\n1296\n−1.15\n판매\n959\n1.29\n    판매\n1228\n−1.19\n상품\n1003\n1.25\n    출시\n1190\n−1.28\n가격\n528\n1.05\n    키트\n664\n−1.29\ncu\n514\n0.36\n    업계\n901\n−1.79\n맥주\n452\n−0.02\n    서비스\n745\n−2.86\n소주\n492\n−0.52\n  \n  \n  \n\n\n\n\n\n주류와 관련하여 GS25는 ‘소주’, ’맥주’가, 세븐일레븐은 ’와인’이 상대적으로 빈도가 나타남.\nGS25의 경우, CU 언급이 많은 것으로 보아 직접적인 비교대상임을 알 수 있음.\n\n\n\n1.0.4.2 GS25, CU\n\n\nCode\nweighted_log_odds_df2 <-\n  bind_rows(GS25_tk, CU_tk, .id = \"party\") %>% \n  bind_log_odds(set = party,\n                feature = word, \n                n = n) %>% \n  arrange(-log_odds_weighted)\n\n\n\n\nCode\nlibrary(gt)\nlibrary(dplyr)\n\nGS25.CU_df <- bind_cols(\n  weighted_log_odds_df2 %>%   \n  group_by(party = ifelse(party == 1, \"GS25\", \"CU\")) %>% \n  arrange(party) %>% \n  select(-party) %>%\n  head(15),\n  \n  weighted_log_odds_df2 %>%   \n  group_by(party = ifelse(party == 1, \"GS25\", \"CU\")) %>% \n  arrange(desc(party)) %>% \n  select(-party) %>%\n  head(15) \n  ) \n\nGS25.CU_df <- GS25.CU_df[-c(1,5)]\n\nGS25.CU_df %>%\n  gt() %>% tab_header(\n  \"상대적으로 많이 사용한 단어\"\n  ) %>% tab_spanner(\n    label = \"GS25 기준\",\n    columns = 1:3\n  ) %>% tab_spanner(\n    label = \"CU 기준\",\n    columns = 4:6\n  ) %>% cols_label(\n    word...2 = \"명사\",\n    n...3 = \"빈도\",\n    log_odds_weighted...4 = \"가중상대빈도\",\n    word...6 = \"명사\",\n    n...7 = \"빈도\",\n    log_odds_weighted...8 = \"가중상대빈도\"\n  ) %>% fmt_number(\n    columns = starts_with(\"log\"), \n    decimals = 2\n  )\n\n\n\n\n\n\n  \n    \n      상대적으로 많이 사용한 단어\n    \n    \n  \n  \n    \n      \n        GS25 기준\n      \n      \n        CU 기준\n      \n    \n    \n      명사\n      빈도\n      가중상대빈도\n      명사\n      빈도\n      가중상대빈도\n    \n  \n  \n    제품\n648\n17.75\n소주\n791\n20.51\n    인기\n634\n17.54\ngs25는\n787\n20.46\n    들이\n624\n17.40\ncu\n719\n19.50\n    서비스\n1047\n1.92\n판매\n1228\n1.03\n    맥주\n906\n1.50\n고객\n647\n0.31\n    업계\n1135\n1.20\n점포\n626\n0.10\n    매출\n868\n1.18\n운영\n781\n−0.36\n    출시\n1408\n0.81\n상품\n1296\n−0.60\n    가격\n805\n0.78\n키트\n664\n−0.65\n    키트\n793\n0.64\n가격\n660\n−0.80\n    상품\n1493\n0.59\n출시\n1190\n−0.83\n    운영\n890\n0.36\n매출\n673\n−1.21\n    점포\n668\n−0.10\n업계\n901\n−1.23\n    고객\n669\n−0.30\n맥주\n672\n−1.54\n    판매\n1190\n−1.02\n서비스\n745\n−1.97\n  \n  \n  \n\n\n\n\n\n주류와 관련하여 GS25는 ‘맥주’가, CU는 ’소주’가 상대적으로 빈도가 높게 나타남. 1개월 정보량에서는 GS25의 ’소주’ 단어빈도가 앞도적으로 높았으나 1년 정보량을 기준으로 하였을 때는 다른 양상을 보이고 있음을 확인함.\n\n\n\n1.0.4.3 세븐일레븐, CU\n\n\nCode\nweighted_log_odds_df3 <-\n  bind_rows(seven_tk, CU_tk, .id = \"party\") %>% \n  bind_log_odds(set = party,\n                feature = word, \n                n = n) %>% \n  arrange(-log_odds_weighted)\n\n\n\n\nCode\nlibrary(gt)\nlibrary(dplyr)\n\nseven.CU_df <- bind_cols(\n  weighted_log_odds_df3 %>%   \n  group_by(party = ifelse(party == 1, \"세븐일레븐\", \"CU\")) %>% \n  arrange(party) %>% \n  select(-party) %>%\n  head(15),\n  \n  weighted_log_odds_df2 %>%   \n  group_by(party = ifelse(party == 1, \"세븐일레븐\", \"CU\")) %>% \n  arrange(desc(party)) %>% \n  select(-party) %>%\n  head(15) \n  ) \n\nseven.CU_df <- seven.CU_df[-c(1,5)]\n\nseven.CU_df %>%\n  gt() %>% tab_header(\n  \"상대적으로 많이 사용한 단어\"\n  ) %>% tab_spanner(\n    label = \"세븐일레븐 기준\",\n    columns = 1:3\n  ) %>% tab_spanner(\n    label = \"CU 기준\",\n    columns = 4:6\n  ) %>% cols_label(\n    word...2 = \"명사\",\n    n...3 = \"빈도\",\n    log_odds_weighted...4 = \"가중상대빈도\",\n    word...6 = \"명사\",\n    n...7 = \"빈도\",\n    log_odds_weighted...8 = \"가중상대빈도\"\n  ) %>% fmt_number(\n    columns = starts_with(\"log\"), \n    decimals = 2\n  )\n\n\n\n\n\n\n  \n    \n      상대적으로 많이 사용한 단어\n    \n    \n  \n  \n    \n      \n        세븐일레븐 기준\n      \n      \n        CU 기준\n      \n    \n    \n      명사\n      빈도\n      가중상대빈도\n      명사\n      빈도\n      가중상대빈도\n    \n  \n  \n    운영\n890\n18.87\n소주\n791\n20.51\n    매출\n868\n18.62\ngs25는\n787\n20.46\n    고객\n669\n16.20\ncu\n719\n19.50\n    점포\n668\n16.18\n판매\n1228\n1.03\n    제품\n648\n15.92\n고객\n647\n0.31\n    인기\n634\n15.74\n점포\n626\n0.10\n    맥주\n906\n0.82\n운영\n781\n−0.36\n    가격\n805\n−0.74\n상품\n1296\n−0.60\n    키트\n793\n−1.18\n키트\n664\n−0.65\n    출시\n1408\n−1.19\n가격\n660\n−0.80\n    상품\n1493\n−1.28\n출시\n1190\n−0.83\n    들이\n624\n−1.29\n매출\n673\n−1.21\n    업계\n1135\n−1.29\n업계\n901\n−1.23\n    서비스\n1047\n−1.70\n맥주\n672\n−1.54\n    판매\n1190\n−2.62\n서비스\n745\n−1.97\n  \n  \n  \n\n\n\n\n\n주류와 관련하여 세븐일레븐은 ’맥주’가, CU는 ’소주’가 상대적으로 빈도가 높게 나타남.\n\n\n\n\n1.0.5 감정분석\n\n1.0.5.1 사전 데이터 프레임 만들기\n\n\nCode\n# pkg_v <- c(\"tidyverse\", \"tidytext\", \"epubr\", \"RcppMeCab\", \"KoNLP\" )\n# lapply(pkg_v, require, ch = T)\n\n# url_v <- \"https://github.com/park1200656/KnuSentiLex/archive/refs/heads/master.zip\"\n# dest_v <- \"data/knusenti.zip\"\n# download.file(url = url_v, destfile = dest_v, mode = \"wb\")\n\n# unzip(\"knusenti.zip\", exdir=outPath)\n\n\n\n\nCode\nsenti_name_v <- list.files(\"data/knusenti/KnuSentiLex-master/.\")[9]\nsenti_dic_df <- read_tsv(str_c(\"data/knusenti/KnuSentiLex-master/\", senti_name_v), col_names = F)\nsenti_dic_df <- senti_dic_df %>% rename(word = X1, sScore = X2)\nknu_dic_df <- senti_dic_df %>% \n  filter(!is.na(sScore))\n\n\n\n\n1.0.5.2 GS25\n\n\nCode\nGS25_senti_df <- GS25_df2 %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  count(word, sScore, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  mutate(word = reorder(word, n)) %>% \n  slice_head(n = 20)\n\nGS25_senti_df %>% \n  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +\n    labs(title = \"GS25 감정빈도 분석\")\n\n\n\n\n\n\nGS25 긍정 이미지 : ‘할인’, ‘이벤트’, ‘혜택’ (할인 위주)\nGS25 부정 이미지 : ‘부담’, ‘화재’ 단어의 경우 부정적인 단어를 활용하여 마케팅을 하면서 나타남. ‘편의점 택배 부담없이 GS25, 반값택배’, ‘화재 시, GS25 소화기 제공’ 문구 활용을 볼 수 있음. ’피해’의 경우, ’국내 최초 가맹점 사기 피해 보상 보험 지원’과 ’남혐 논란, GS25피해 CU로’라는 내용으로 살펴볼 수 있음.\n\n\n\n1.0.5.3 세븐일레븐\n\n\nCode\nseven_senti_df <- seven_df2 %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  count(word, sScore, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  mutate(word = reorder(word, n)) %>% \n  slice_head(n = 20)\n\nseven_senti_df %>% \n  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +\n    labs(title = \"세븐일레븐 감정빈도 분석\")\n\n\n\n\n\n\n세븐일레븐 긍정 이미지 : ‘할인’, ‘혜택’, ‘이벤트’ (할인 중심)\n세븐일레븐 부정 이미지 : ‘부담’의 경우 ’학생 맞춤형 도시락…부담을 낮췄다’, ‘식사 후 커피 부담되는데..반값커피’ 등 물가 부담과 대비되는 제품을 출시하면서 단어 빈도가 높아짐. ’피해’는 지난 9월에 발생한 태풍 피해를 의미하고 있음.\n\n\n\n1.0.5.4 CU\n\n\nCode\nCU_senti_df <- CU_df2 %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  count(word, sScore, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  mutate(word = reorder(word, n)) %>% \n  slice_head(n = 20)\n\nCU_senti_df %>% \n  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +\n    labs(title = \"CU 감정빈도 분석\")\n\n\n\n\n\n\nCU 긍정 이미지 : ‘할인’, ‘이벤트’, ‘혜택’ (할인 중심)\nCU 부정 이미지 : ’부담’의 경우, ’부담없이’라는 카피를 반복적으로 사용함으로써 빈도가 높게 나타남.\n\n\n\n\n1.0.6 감정분석 - 긍정어, 부정어\n\n1.0.6.1 GS25\n\n\nCode\nGS25_df2 %>% \n  unnest_tokens(word, text) %>% \n  left_join(knu_dic_df) %>% \n  mutate(sScore = ifelse(sScore >= 1, \"긍정\",\n                         ifelse(sScore <= -1, \"부정\", \"중립\"))) %>% \n  count(sScore)\n\n\n# A tibble: 4 × 2\n  sScore      n\n  <chr>   <int>\n1 긍정     3326\n2 부정      959\n3 중립      104\n4 <NA>   248995\n\n\nCode\nGS25_df2 %>%   \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>%\n  mutate(label = ifelse(sScore > 0, \"1\", ifelse(sScore < 0, \"0\", \"2\"))) %>%\n  filter(label != \"중립\") %>%\n  count(word, emotion, label, sort = T) %>%\n  filter(str_length(word) > 1) %>%\n  group_by(label = ifelse(label > 0, \"긍정\", \"부정\")) %>%\n  slice_head(n = 15) %>%\n  ggplot(aes(x = n,\n             y = reorder(word, n), fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\") +\n  labs(title = \"GS25 긍정어 부정어\")\n\n\n\n\n\n\n\n1.0.6.2 세븐일레븐\n\n\nCode\nseven_df2 %>% \n  unnest_tokens(word, text) %>% \n  left_join(knu_dic_df) %>% \n  mutate(sScore = ifelse(sScore >= 1, \"긍정\",\n                         ifelse(sScore <= -1, \"부정\", \"중립\"))) %>% \n  count(sScore)\n\n\n# A tibble: 4 × 2\n  sScore      n\n  <chr>   <int>\n1 긍정     2621\n2 부정      674\n3 중립       73\n4 <NA>   192471\n\n\nCode\nseven_df2 %>%   \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>%\n  mutate(label = ifelse(sScore > 0, \"1\", ifelse(sScore < 0, \"0\", \"2\"))) %>%\n  filter(label != \"중립\") %>%\n  count(word, emotion, label, sort = T) %>%\n  filter(str_length(word) > 1) %>%\n  group_by(label = ifelse(label > 0, \"긍정\", \"부정\")) %>%\n  slice_head(n = 15) %>%\n  ggplot(aes(x = n,\n             y = reorder(word, n), fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\") +\n  labs(title = \"세븐일레븐 긍정어 부정어\")\n\n\n\n\n\n\n\n1.0.6.3 CU\n\n\nCode\nCU_df2 %>% \n  unnest_tokens(word, text) %>% \n  left_join(knu_dic_df) %>% \n  mutate(sScore = ifelse(sScore >= 1, \"긍정\",\n                         ifelse(sScore <= -1, \"부정\", \"중립\"))) %>% \n  count(sScore)\n\n\n# A tibble: 4 × 2\n  sScore      n\n  <chr>   <int>\n1 긍정     4110\n2 부정     1014\n3 중립       98\n4 <NA>   294150\n\n\nCode\nCU_df2 %>%   \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>%\n  mutate(label = ifelse(sScore > 0, \"1\", ifelse(sScore < 0, \"0\", \"2\"))) %>%\n  filter(label != \"중립\") %>%\n  count(word, emotion, label, sort = T) %>%\n  filter(str_length(word) > 1) %>%\n  group_by(label = ifelse(label > 0, \"긍정\", \"부정\")) %>%\n  slice_head(n = 15) %>%\n  ggplot(aes(x = n,\n             y = reorder(word, n), fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\") +\n  labs(title = \"CU 긍정어 부정어\")\n\n\n\n\n\n\n\n\n1.0.7 토픽모델링\n\n1.0.7.1 GS25\n\n\nCode\nGS25_topic_tk <- GS25_df2 %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F)\n\nGS25_topic_tk <- \nGS25_topic_tk %>% \n  filter(!word %in% c(\"gs\", \"gs25\", \"리테일\", \"기자\", \"편의점\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nGS25_combined_df <-\n  GS25_topic_tk %>%\n  group_by(ID) %>%\n  summarise(text2 = str_flatten(word, \" \")) %>%\n  ungroup() %>% \n  inner_join(GS25_df2, by = \"ID\")\n\nlibrary(stm)\nlibrary(tm)\n\nprocessed <- \n  GS25_df2 %>% textProcessor(\n    documents = GS25_combined_df$text2,\n    metadata = .,\n    wordLengths = c(2, Inf)\n    )\n\n\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n\n\nCode\nout <-\n  prepDocuments(processed$documents,\n                processed$vocab,\n                processed$meta, \n                lower.thresh = 0)\ndocs <- out$documents\nvocab <- out$vocab\nmeta <- out$meta\ntopicN <- c(3, 10)\n#storage <- searchK(out$documents, out$vocab, K = topicN)\n\nGS25_stm_fit <-\n  stm(\n    documents = docs,\n    vocab = vocab,\n    K = 6,\n    data = meta,\n    max.em.its = 75,\n    init.type = \"Spectral\",\n    seed = 25,\n    verbose = F\n  )\n\n#labelTopics(GS25_stm_fit)\n\nGS25_topic_name <- tibble(topic = 1:6,\n                     name = c(\"1. 사업 경영\",\n                              \"2. 점포 운영\",\n                              \"3. 경쟁\",\n                              \"4. 판매, 출시\",\n                              \"5. 배송, 온라인\",\n                              \"6. 프로모션\"))\n\nGS25_td_beta <- GS25_stm_fit %>% tidy(matrix = 'beta') \nGS25_topic_name <- GS25_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 7) %>% \n  left_join(GS25_topic_name, by = \"topic\")\n\nGS25_topic_name %>% \n  ggplot(aes(x = beta, \n             y = reorder_within(term, beta, name),  # 각 주제별로 재정렬\n             fill = name)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~name, scales = \"free\") +\n  scale_y_reordered() +                             # 재정렬한 y축의 값 설정\n  labs(x = expression(\"단어 확률분포: \"~beta), y = NULL,\n       title = \"GS25 주제별 단어 확률 분포\",\n       subtitle = \"주제별로 다른 단어들로 군집\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n\n1.0.7.2 세븐일레븐\n\n\nCode\nseven_topic_tk <- seven_df2 %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F)\n\nseven_topic_tk <- \nseven_topic_tk %>% \n  filter(!word %in% c(\"세븐일레븐\", \"기자\", \"편의점\", \"롯데\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nseven_combined_df <-\n  seven_topic_tk %>%\n  group_by(ID) %>%\n  summarise(text2 = str_flatten(word, \" \")) %>%\n  ungroup() %>% \n  inner_join(seven_df2, by = \"ID\")\n\nlibrary(stm)\nlibrary(tm)\n\nprocessed <- \n  seven_df2 %>% textProcessor(\n    documents = seven_combined_df$text2,\n    metadata = .,\n    wordLengths = c(2, Inf)\n    )\n\n\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n\n\nCode\nout <-\n  prepDocuments(processed$documents,\n                processed$vocab,\n                processed$meta, \n                lower.thresh = 0)\ndocs <- out$documents\nvocab <- out$vocab\nmeta <- out$meta\ntopicN <- c(3, 10)\n#storage <- searchK(out$documents, out$vocab, K = topicN)\n\nseven_stm_fit <-\n  stm(\n    documents = docs,\n    vocab = vocab,\n    K = 6,\n    data = meta,\n    max.em.its = 75,\n    init.type = \"Spectral\",\n    seed = 25,\n    verbose = F\n  )\n\n#labelTopics(seven_stm_fit)\n\nseven_topic_name <- tibble(topic = 1:6,\n                     name = c(\"1. 신제품\",\n                              \"2. 프로모션\",\n                              \"3. 콜라보레이션\",\n                              \"4. 코로나 상황\",\n                              \"5. 매출\",\n                              \"6. 배달, 모빌리티\"))\n\nseven_td_beta <- seven_stm_fit %>% tidy(matrix = 'beta') \nseven_topic_name <- seven_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 7) %>% \n  left_join(seven_topic_name, by = \"topic\")\n\nseven_topic_name %>% \n  ggplot(aes(x = beta, \n             y = reorder_within(term, beta, name),  # 각 주제별로 재정렬\n             fill = name)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~name, scales = \"free\") +\n  scale_y_reordered() +                             # 재정렬한 y축의 값 설정\n  labs(x = expression(\"단어 확률분포: \"~beta), y = NULL,\n       title = \"세븐일레븐 주제별 단어 확률 분포\",\n       subtitle = \"주제별로 다른 단어들로 군집\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n\n1.0.7.3 CU\n\n\nCode\nCU_topic_tk <- CU_df2 %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F)\n\nCU_topic_tk <- \nCU_topic_tk %>% \n  filter(!word %in% c(\"cu\", \"기자\", \"편의점\", \"리테일\", \"bgf\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nCU_combined_df <-\n  CU_topic_tk %>%\n  group_by(ID) %>%\n  summarise(text2 = str_flatten(word, \" \")) %>%\n  ungroup() %>% \n  inner_join(CU_df2, by = \"ID\")\n\nlibrary(stm)\nlibrary(tm)\n\nprocessed <- \n  CU_df2 %>% textProcessor(\n    documents = CU_combined_df$text2,\n    metadata = .,\n    wordLengths = c(2, Inf)\n    )\n\n\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n\n\nCode\nout <-\n  prepDocuments(processed$documents,\n                processed$vocab,\n                processed$meta, \n                lower.thresh = 0)\ndocs <- out$documents\nvocab <- out$vocab\nmeta <- out$meta\ntopicN <- c(3, 10)\n#storage <- searchK(out$documents, out$vocab, K = topicN)\n\nCU_stm_fit <-\n  stm(\n    documents = docs,\n    vocab = vocab,\n    K = 6,\n    data = meta,\n    max.em.its = 75,\n    init.type = \"Spectral\",\n    seed = 25,\n    verbose = F\n  )\n\n#labelTopics(CU_stm_fit)\n\nCU_topic_name <- tibble(topic = 1:6,\n                     name = c(\"1. 제휴, 운영\",\n                              \"2. 경쟁\",\n                              \"3. 코로나 상황\",\n                              \"4. 매출, 운영\",\n                              \"5. 출시, 판매\",\n                              \"6. 브랜드 캠페인\"))\n\nCU_td_beta <- CU_stm_fit %>% tidy(matrix = 'beta') \nCU_topic_name <- CU_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 7) %>% \n  left_join(CU_topic_name, by = \"topic\")\n\nCU_topic_name %>% \n  ggplot(aes(x = beta, \n             y = reorder_within(term, beta, name),  # 각 주제별로 재정렬\n             fill = name)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~name, scales = \"free\") +\n  scale_y_reordered() +                             # 재정렬한 y축의 값 설정\n  labs(x = expression(\"단어 확률분포: \"~beta), y = NULL,\n       title = \"CU 주제별 단어 확률 분포\",\n       subtitle = \"주제별로 다른 단어들로 군집\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n\n\n1.0.8 관련보도 상위 주제어\n\n1.0.8.1 GS25\n\n\nCode\nGS25_td_gamma <- GS25_stm_fit %>% tidy(matrix = \"gamma\") \nGS25_top_terms <- \nGS25_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 5) %>% \n  select(topic, term) %>% \n  summarise(terms = str_flatten(term, collapse = \", \")) \n\nGS25_gamma_terms <- \nGS25_td_gamma %>% \n  group_by(topic) %>% \n  summarise(gamma = mean(gamma)) %>% \n  left_join(GS25_top_terms, by = 'topic') %>% \n  left_join(GS25_topic_name, by = 'topic')\n  \nGS25_gamma_terms %>% \n  \n  ggplot(aes(x = gamma, y = reorder(name, gamma), fill = name)) +\n  geom_col(show.legend = F) +\n  geom_text(aes(label = round(gamma, 2)), # 소수점 2자리 \n            hjust = 1.15) +                # 라벨을 막대도표 안쪽으로 이동\n  geom_text(aes(label = terms), \n            hjust = -0.05) +              # 단어를 막대도표 바깥으로 이동\n  #scale_x_continuous(expand = c(0, 0),    # x축 막대 위치를 Y축쪽으로 조정\n  #                   limit = c(0, 1)) +   # x축 범위 설정\n  labs(x = expression(\"문서 확률분포\"~(gamma)), y = NULL,\n       title = \"GS25 관련보도 상위 주제어\",\n       subtitle = \"주제별로 기여도가 높은 단어 중심\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n’사업경영’과 관련하여 GS25가 쿠캣마켓과 요기요를 인수한 점을 확인함. 동시에 세븐일레븐이 미니스톱을 인수한 내용도 함께 살펴볼 수 있음.\n소주, 맥주, 코로나진단키트가 GS25의 주요 판매품인 것을 확인할 수 있음.\n은행, 택배의 역할들을 가져오려는 모습들이 보이고, 운영에 있어 컨테이너 무인점포를 운영한 것이 큰 이슈가 됨.\n\n\n\n1.0.8.2 세븐일레븐\n\n\nCode\nseven_td_gamma <- seven_stm_fit %>% tidy(matrix = \"gamma\") \nseven_top_terms <- \nseven_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 5) %>% \n  select(topic, term) %>% \n  summarise(terms = str_flatten(term, collapse = \", \")) \n\nseven_gamma_terms <- \nseven_td_gamma %>% \n  group_by(topic) %>% \n  summarise(gamma = mean(gamma)) %>% \n  left_join(seven_top_terms, by = 'topic') %>% \n  left_join(seven_topic_name, by = 'topic')\n\nseven_gamma_terms %>% \n  \n  ggplot(aes(x = gamma, y = reorder(name, gamma), fill = name)) +\n  geom_col(show.legend = F) +\n  geom_text(aes(label = round(gamma, 2)), # 소수점 2자리 \n            hjust = 1.15) +                # 라벨을 막대도표 안쪽으로 이동\n  geom_text(aes(label = terms), \n            hjust = -0.05) +              # 단어를 막대도표 바깥으로 이동\n  #scale_x_continuous(expand = c(0, 0),    # x축 막대 위치를 Y축쪽으로 조정\n  #                   limit = c(0, 1)) +   # x축 범위 설정\n  labs(x = expression(\"문서 확률분포\"~(gamma)), y = NULL,\n       title = \"세븐일레븐 관련보도 상위 주제어\",\n       subtitle = \"주제별로 기여도가 높은 단어 중심\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n와인이 세븐일레븐의 매출에 큰 영향을 미치고 있음을 짐작할 수 있음.\n다른 편의점과 달리 배달, 로봇, 배송 등의 키워드를 통해 모빌리티에 큰 관심을 살펴볼 수 있음.\n포켓몬 캐릭터를 활용한 콜라보레이션이 큰 이슈가 되었음.\n\n\n\n1.0.8.3 CU\n\n\nCode\nCU_td_gamma <- CU_stm_fit %>% tidy(matrix = \"gamma\") \nCU_top_terms <- \nCU_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 5) %>% \n  select(topic, term) %>% \n  summarise(terms = str_flatten(term, collapse = \", \")) \n\nCU_gamma_terms <- \nCU_td_gamma %>% \n  group_by(topic) %>% \n  summarise(gamma = mean(gamma)) %>% \n  left_join(CU_top_terms, by = 'topic') %>% \n  left_join(CU_topic_name, by = 'topic')\n\nCU_gamma_terms %>% \n  \n  ggplot(aes(x = gamma, y = reorder(name, gamma), fill = name)) +\n  geom_col(show.legend = F) +\n  geom_text(aes(label = round(gamma, 2)), # 소수점 2자리 \n            hjust = 1.15) +                # 라벨을 막대도표 안쪽으로 이동\n  geom_text(aes(label = terms), \n            hjust = -0.05) +              # 단어를 막대도표 바깥으로 이동\n  #scale_x_continuous(expand = c(0, 0),    # x축 막대 위치를 Y축쪽으로 조정\n  #                   limit = c(0, 1)) +   # x축 범위 설정\n  labs(x = expression(\"문서 확률분포\"~(gamma)), y = NULL,\n       title = \"CU 관련보도 상위 주제어\",\n       subtitle = \"주제별로 기여도가 높은 단어 중심\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n다른 편의점과 달리, 신제품 출시보다는 브랜드 캠페인에 많은 노력을 기울임.\n마케팅에 있어서도 특정 브랜드, 캐릭터와의 콜라보레이션보다는 카드 제휴, 할인 행사 등 자체적으로 진행하는 행사가 주를 이룸.\n\n\n\n\n1.0.9 결론\n\n1.0.9.1 평판 비교\n\n\n공통점\n\n편의점 3사가 공통적으로 ‘코로나 자가진단키트’, ’주류’와 관련된 단어들이 다수 언급되었습니다. 그 배경을 살펴보면 다음과 같습니다. 코로나 상황에서 자가진단키트가 판매가능해지자 편의점들은 발빠르게 판매를 시작하였고, 동네를 기점으로 점포들이 많이 형성되어 있어서 소비자들이 쉽게 접근할 수 있었습니다. 더불어 편의점의 주요 판매제품이 주류임을 인지하고 이와 관련하여 단독판매, 프리미엄 매장, 제품 확대 등의 노력들이 진행하였습니다.\n\n\nGS25 : 스타트업 인수를 통해 사업 고도화를 진행하고, 은행 및 택배 등 다른 산업군의 역할들을 편의점에 적용하려는 시도들이 많이 언급되었습니다. 즉, ’사업확장’을 중심으로 평판을 형성하고 있음을 확인하였습니다.\n세븐일레븐 : 주류 중 와인 상품 다양화를 진행하고, 포켓몬 캐릭터를 활용하여 제품을 판매하고 팝업스토어를 운영하였습니다. 즉, ’제품 브랜딩’을 중심으로 평판을 형성하고 있음을 확인하였습니다. 더불어 모빌리티 사업의 확장과 관련하여서도 높은 빈도로 언급되었습니다.\nCU : 카드 제휴 및 할인 행사 등의 프로모션을 중심으로 마케팅을 진행하고, 메타버스와 결합하거나 친환경을 주제로 회사 브랜드를 형성하는데 집중하고 있습니다. 즉, ’회사 브랜드 캠페인’을 중심으로 평판을 형성하고 있음을 확인하였습니다.\n\n\n\n1.0.9.2 평판 전략 방향\n\nGS25는 마을 반경 안에서 자주 방문하는 곳들을 통합하려는 시도와 함께, 화재시 소화기를 무상 제공하는 등 일상과 밀접한 캠페인을 진행하였습니다. 즉, ’동네 주요 기점’으로 성장하려는 노력을 기사를 통해 잘 전달되었습니다.\n세븐일레븐은 제품에 있어 타사와 차별화를 가지려고 노력하였습니다. 이는 곧 다른 편의점이 아닌 해당 편의점을 방문해야만 하는 이유를 제시해줌으로 좋은 전략이라고 볼 수 있습니다. 이러한 전략을 기사를 통해 더 견고히 하려는 모습이 보였습니다.\nCU는 기능적인 프로모션과 회사 브랜딩에 집중하였지만 각각의 요소들이 일관된 메시지(혹은 컨셉)를 보여주고 있지는 않습니다. 경쟁력을 가지기 위해서는 메시지를 분명히 하고 프로모션, 사업확장, 캠페인 등에 있어 유기적으로 일관된 컨셉을 보여주어야 할 것입니다. 그래야만 회사에서 효과적으로 평판 관리를 할 수 있을 뿐만 아니라 장기적으로 충성고객을 형성할 수 있을 것입니다."
  },
  {
    "objectID": "8th_data.html",
    "href": "8th_data.html",
    "title": "2  언론보도 분석을 통한 GS25의 연도별 평판 비교분석",
    "section": "",
    "text": "2.0.2 자료 수집\n\n2.0.2.1 패키지 설치\n\n\nCode\npackage_list <- c(\"tidyverse\", \"tidytext\", \"readxl\", \"kableExtra\", \n                  \"multilinguer\", \"RcppMeCab\", \"KoNLP\", \"lubridate\", \n                  \"tidylo\", \"stm\", \"reshape2\", \"dplyr\", \"ggplot2\", \n                  \"stringr\", \"rvest\", \"wordcloud\", \"tm\", \"VennDiagram\", \"gt\")\n \n#package_list_installed <- package_list %in% installed.packages()[,\"Package\"]\n# new_pkg <- package_list[!package_list_installed]\n# if(length(new_pkg)) install.packages(new_pkg)\n\nlapply(package_list, require, character.only = TRUE)\n\n\n\n\n2.0.2.2 데이터셋 수집\n\n\nCode\nGS25_2021_df <- readxl::read_excel(\"GS25_21_data.xlsx\") %>% \n  select(제목, 본문)\n\nGS25_2022_df <- readxl::read_excel(\"GS25_22_data.xlsx\") %>% \n  select(제목, 본문)\n\n\n\n\n\n2.0.3 자료분석-총빈도\n\n2.0.3.1 GS25 (2021. 01. 01. ~ 2021. 10. 31. / 약 10개월)\n\n\nCode\nGS25_2021_df <- GS25_2021_df %>% \n  distinct(제목, .keep_all = T) %>% \n  mutate(ID = factor(row_number())) %>% \n  mutate(label = \"0\") %>%\n  unite(제목, 본문, col = \"text\", sep = \" \") %>% \n  mutate(text = str_squish(text))\n\nGS25_2021_tk <- GS25_2021_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F) %>%\n  count(word, sort = T)\n\nGS25_2021_tk <- \nGS25_2021_tk %>% \n  filter(!word %in% c(\"gs\", \"gs25\", \"리테일\", \"기자\", \"편의점\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\")) %>%\n  filter(str_length(word) > 1) %>%\n  slice_max(n, n = 15) %>% \n  mutate(word = reorder(word, n))\n\nGS25_2021_tk %>%\n  ggplot(aes(word, n)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"GS25 총빈도 (2021)\")\n\n\n\n\n\n\n\n2.0.3.2 GS25 (2022. 01. 01. ~ 2022. 10. 31. / 약 10개월)\n\n\nCode\nGS25_2022_df <- GS25_2022_df %>% \n  distinct(제목, .keep_all = T) %>% \n  mutate(ID = factor(row_number())) %>% \n  mutate(label = \"0\") %>%\n  unite(제목, 본문, col = \"text\", sep = \" \") %>% \n  mutate(text = str_squish(text))\n\nGS25_2022_tk <- GS25_2022_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F) %>%\n  count(word, sort = T)\n\nGS25_2022_tk <- \nGS25_2022_tk %>% \n  filter(!word %in% c(\"gs\", \"gs25\", \"리테일\", \"기자\", \"편의점\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\")) %>%\n  filter(str_length(word) > 1) %>%\n  slice_max(n, n = 15) %>% \n  mutate(word = reorder(word, n))\n\nGS25_2022_tk %>%\n  ggplot(aes(word, n)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"GS25 총빈도 (2022)\")\n\n\n\n\n\n\n\n2.0.3.3 분석\n\n주류와 관련하여 2021년에는 ’맥주’가, 2022년에는 ’소주’가 총빈도가 높게 나타남.\n2021년에는 ‘배달’, ‘온라인’ 등 비대면 관련 서비스 키워드에 눈에 띔.\n2021년과 2022년을 비교하였을 때, CU와 함께 언급이 더 많아졌음을 알 수 있음.\n\n\n\n\n2.0.4 자료분석-상대빈도\n\n\nCode\nweighted_log_odds_df <-\n  bind_rows(GS25_2021_tk, GS25_2022_tk, .id = \"party\") %>% \n  bind_log_odds(set = party,\n                feature = word, \n                n = n) %>% \n  arrange(-log_odds_weighted)\n\n\n\n\nCode\nlibrary(gt)\nlibrary(dplyr)\n\nGS25_2021.2022_df <- bind_cols(\n  weighted_log_odds_df %>%   \n  group_by(party = ifelse(party == 1, \"GS25(2021)\", \"GS25(2022)\")) %>% \n  arrange(party) %>% \n  select(-party) %>%\n  head(15),\n  \n  weighted_log_odds_df %>%   \n  group_by(party = ifelse(party == 1, \"GS25(2021)\", \"GS25(2022)\")) %>% \n  arrange(desc(party)) %>% \n  select(-party) %>%\n  head(15) \n  ) \n\nGS25_2021.2022_df <- GS25_2021.2022_df[-c(1,5)]\n\nGS25_2021.2022_df %>%\n  gt() %>% tab_header(\n  \"상대적으로 많이 사용한 단어\"\n  ) %>% tab_spanner(\n    label = \"GS25 (2021)\",\n    columns = 1:3\n  ) %>% tab_spanner(\n    label = \"GS25 (2022)\",\n    columns = 4:6\n  ) %>% cols_label(\n    word...2 = \"명사\",\n    n...3 = \"빈도\",\n    log_odds_weighted...4 = \"가중상대빈도\",\n    word...6 = \"명사\",\n    n...7 = \"빈도\",\n    log_odds_weighted...8 = \"가중상대빈도\"\n  ) %>% fmt_number(\n    columns = starts_with(\"log\"), \n    decimals = 2\n  )\n\n\n\n\n\n\n  \n    \n      상대적으로 많이 사용한 단어\n    \n    \n  \n  \n    \n      \n        GS25 (2021)\n      \n      \n        GS25 (2022)\n      \n    \n    \n      명사\n      빈도\n      가중상대빈도\n      명사\n      빈도\n      가중상대빈도\n    \n  \n  \n    배달\n723\n19.17\n소주\n798\n20.52\n    논란\n564\n16.79\n키트\n661\n18.55\n    제공\n463\n15.14\n가격\n585\n17.38\n    온라인\n461\n15.11\n제품\n502\n16.04\n    서비스\n996\n4.30\n판매\n1065\n1.09\n    고객\n811\n2.85\ncu\n608\n0.71\n    맥주\n679\n1.17\ngs25는\n652\n0.64\n    상품\n1210\n0.85\n출시\n1048\n0.49\n    매출\n651\n0.76\n업계\n715\n0.21\n    운영\n664\n0.05\n운영\n639\n−0.05\n    업계\n715\n−0.21\n매출\n557\n−0.77\n    출시\n1020\n−0.49\n상품\n1066\n−0.86\n    gs25는\n608\n−0.64\n맥주\n544\n−1.19\n    cu\n558\n−0.71\n고객\n498\n−2.92\n    판매\n965\n−1.08\n서비스\n503\n−4.44\n  \n  \n  \n\n\n\n\n\n\n2.0.5 감정분석\n\n2.0.5.1 사전 데이터 프레임 만들기\n\n\nCode\n# pkg_v <- c(\"tidyverse\", \"tidytext\", \"epubr\", \"RcppMeCab\", \"KoNLP\" )\n# lapply(pkg_v, require, ch = T)\n\n# url_v <- \"https://github.com/park1200656/KnuSentiLex/archive/refs/heads/master.zip\"\n# dest_v <- \"data/knusenti.zip\"\n# download.file(url = url_v, destfile = dest_v, mode = \"wb\")\n\n# unzip(\"knusenti.zip\", exdir=outPath)\n\n\n\n\nCode\nsenti_name_v <- list.files(\"data/knusenti/KnuSentiLex-master/.\")[9]\nsenti_dic_df <- read_tsv(str_c(\"data/knusenti/KnuSentiLex-master/\", senti_name_v), col_names = F)\nsenti_dic_df <- senti_dic_df %>% rename(word = X1, sScore = X2)\nknu_dic_df <- senti_dic_df %>% \n  filter(!is.na(sScore))\n\n\n\n\n2.0.5.2 GS25(2021)\n\n\nCode\nGS25_2021_senti_df <- GS25_2021_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  count(word, sScore, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  mutate(word = reorder(word, n)) %>% \n  slice_head(n = 20)\n\nGS25_2021_senti_df %>% \n  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +\n    labs(title = \"GS25 감정빈도 분석 (2021)\")\n\n\n\n\n\n\n\nCode\nGS25_2021_df %>% \n  unnest_tokens(word, text) %>% \n  left_join(knu_dic_df) %>% \n  mutate(sScore = ifelse(sScore >= 1, \"긍정\",\n                         ifelse(sScore <= -1, \"부정\", \"중립\"))) %>% \n  count(sScore)\n\n\n# A tibble: 4 × 2\n  sScore      n\n  <chr>   <int>\n1 긍정     3123\n2 부정     1041\n3 중립      134\n4 <NA>   218559\n\n\nCode\nGS25_2021_df %>%   \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>%\n  mutate(label = ifelse(sScore > 0, \"1\", ifelse(sScore < 0, \"0\", \"2\"))) %>%\n  filter(label != \"중립\") %>%\n  count(word, emotion, label, sort = T) %>%\n  filter(str_length(word) > 1) %>%\n  group_by(label = ifelse(label > 0, \"긍정\", \"부정\")) %>%\n  slice_head(n = 15) %>%\n  ggplot(aes(x = n,\n             y = reorder(word, n), fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\") +\n  labs(title = \"GS25 긍정어 부정어 (2021)\")\n\n\n\n\n\n\nGS25(2021) 긍정 이미지 : ‘이벤트’, ‘할인’, ‘인기’, ‘혜택’. ‘고급’, ‘최저가’\nGS25(2021) 부정 이미지 : ‘혐오’는 GS25의 홍보포스터가 남성 혐오 논란을 일으키면서 높은 비중을 차지함. ’부담’, ‘화재’ 단어의 경우 부정적인 단어를 활용하여 마케팅을 하면서 나타남. ‘편의점 택배 부담없이 GS25, 반값택배’, ‘화재 시, GS25 소화기 제공’ 문구 활용을 볼 수 있음. ’장애인’의 경우, ’늘봄스토어’를 통해 장애인 취업 기회를 제공한다는 내용임.\n\n\n\n2.0.5.3 GS25(2022)\n\n\nCode\nGS25_2022_senti_df <- GS25_2022_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  count(word, sScore, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  mutate(word = reorder(word, n)) %>% \n  slice_head(n = 20)\n\nGS25_2022_senti_df %>% \n  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +\n    labs(title = \"GS25 감정빈도 분석 (2022)\")\n\n\n\n\n\n\n\nCode\nGS25_2022_df %>% \n  unnest_tokens(word, text) %>% \n  left_join(knu_dic_df) %>% \n  mutate(sScore = ifelse(sScore >= 1, \"긍정\",\n                         ifelse(sScore <= -1, \"부정\", \"중립\"))) %>% \n  count(sScore)\n\n\n# A tibble: 4 × 2\n  sScore      n\n  <chr>   <int>\n1 긍정     2563\n2 부정      754\n3 중립       75\n4 <NA>   199275\n\n\nCode\nGS25_2022_df %>%   \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>%\n  mutate(label = ifelse(sScore > 0, \"1\", ifelse(sScore < 0, \"0\", \"2\"))) %>%\n  filter(label != \"중립\") %>%\n  count(word, emotion, label, sort = T) %>%\n  filter(str_length(word) > 1) %>%\n  group_by(label = ifelse(label > 0, \"긍정\", \"부정\")) %>%\n  slice_head(n = 15) %>%\n  ggplot(aes(x = n,\n             y = reorder(word, n), fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\") +\n  labs(title = \"GS25 긍정어 부정어 (2022)\")\n\n\n\n\n\n\nGS25(2022) 긍정 이미지 : ‘인기’, ‘할인’, ‘이벤트’, ‘혜택’. ‘맛집’, ‘최저가’\nGS25(2022) 부정 이미지 : ‘부담’, ‘화재’ 단어의 경우 부정적인 단어를 활용하여 마케팅을 하면서 나타남. ‘편의점 택배 부담없이 GS25, 반값택배’, ‘화재 시, GS25 소화기 제공’ 문구 활용을 볼 수 있음. ’피해’의 경우, ’국내 최초 가맹점 사기 피해 보상 보험 지원’과 ’남혐 논란, GS25피해 CU로’라는 내용으로 살펴볼 수 있음.\n\n\n\n\n2.0.6 토픽모델링\n\n2.0.6.1 GS25(2021)\n\n\nCode\nGS25_2021_topic_tk <- GS25_2021_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F)\n\nGS25_2021_topic_tk <- \nGS25_2021_topic_tk %>% \n  filter(!word %in% c(\"gs\", \"gs25\", \"리테일\", \"기자\", \"편의점\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nGS25_2021_combined_df <-\n  GS25_2021_topic_tk %>%\n  group_by(ID) %>%\n  summarise(text2 = str_flatten(word, \" \")) %>%\n  ungroup() %>% \n  inner_join(GS25_2021_df, by = \"ID\")\n\nlibrary(stm)\nlibrary(tm)\n\nprocessed <- \n  GS25_2021_df %>% textProcessor(\n    documents = GS25_2021_combined_df$text2,\n    metadata = .,\n    wordLengths = c(2, Inf)\n    )\n\n\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n\n\nCode\nout <-\n  prepDocuments(processed$documents,\n                processed$vocab,\n                processed$meta, \n                lower.thresh = 0)\ndocs <- out$documents\nvocab <- out$vocab\nmeta <- out$meta\ntopicN <- c(3, 10)\n#storage <- searchK(out$documents, out$vocab, K = topicN)\n\nGS25_2021_stm_fit <-\n  stm(\n    documents = docs,\n    vocab = vocab,\n    K = 6,\n    data = meta,\n    max.em.its = 75,\n    init.type = \"Spectral\",\n    seed = 25,\n    verbose = F\n  )\n\n#labelTopics(GS25_stm_fit)\n\nGS25_2021_topic_name <- tibble(topic = 1:6,\n                     name = c(\"1. 혐오 논란\",\n                              \"2. 주류 판매\",\n                              \"3. 운영\",\n                              \"4. 협약\",\n                              \"5. 결제 방식\",\n                              \"6. 배달서비스\"))\n\nGS25_2021_td_beta <- GS25_2021_stm_fit %>% tidy(matrix = 'beta') \nGS25_2021_topic_name <- GS25_2021_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 7) %>% \n  left_join(GS25_2021_topic_name, by = \"topic\")\n\nGS25_2021_topic_name %>% \n  ggplot(aes(x = beta, \n             y = reorder_within(term, beta, name),  # 각 주제별로 재정렬\n             fill = name)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~name, scales = \"free\") +\n  scale_y_reordered() +                             # 재정렬한 y축의 값 설정\n  labs(x = expression(\"단어 확률분포: \"~beta), y = NULL,\n       title = \"GS25 주제별 단어 확률 분포 (2021)\",\n       subtitle = \"주제별로 다른 단어들로 군집\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n\n2.0.6.2 GS25(2022)\n\n\nCode\nGS25_2022_topic_tk <- GS25_2022_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F)\n\nGS25_2022_topic_tk <- \nGS25_2022_topic_tk %>% \n  filter(!word %in% c(\"gs\", \"gs25\", \"리테일\", \"기자\", \"편의점\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nGS25_2022_combined_df <-\n  GS25_2022_topic_tk %>%\n  group_by(ID) %>%\n  summarise(text2 = str_flatten(word, \" \")) %>%\n  ungroup() %>% \n  inner_join(GS25_2021_df, by = \"ID\")\n\nlibrary(stm)\nlibrary(tm)\n\nprocessed <- \n  GS25_2022_df %>% textProcessor(\n    documents = GS25_2022_combined_df$text2,\n    metadata = .,\n    wordLengths = c(2, Inf)\n    )\n\n\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n\n\nCode\nout <-\n  prepDocuments(processed$documents,\n                processed$vocab,\n                processed$meta, \n                lower.thresh = 0)\ndocs <- out$documents\nvocab <- out$vocab\nmeta <- out$meta\ntopicN <- c(3, 10)\n#storage <- searchK(out$documents, out$vocab, K = topicN)\n\nGS25_2022_stm_fit <-\n  stm(\n    documents = docs,\n    vocab = vocab,\n    K = 6,\n    data = meta,\n    max.em.its = 75,\n    init.type = \"Spectral\",\n    seed = 25,\n    verbose = F\n  )\n\n#labelTopics(GS25_stm_fit)\n\nGS25_2022_topic_name <- tibble(topic = 1:6,\n                     name = c(\"1. 주류 판매\",\n                              \"2. 경쟁\",\n                              \"3. 도시락 상품\",\n                              \"4. 메타버스 활용\",\n                              \"5. 코로나 상황\",\n                              \"6. 캐릭터 상품\"))\n\nGS25_2022_td_beta <- GS25_2022_stm_fit %>% tidy(matrix = 'beta') \nGS25_2022_topic_name <- GS25_2022_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 7) %>% \n  left_join(GS25_2022_topic_name, by = \"topic\")\n\nGS25_2022_topic_name %>% \n  ggplot(aes(x = beta, \n             y = reorder_within(term, beta, name),  # 각 주제별로 재정렬\n             fill = name)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~name, scales = \"free\") +\n  scale_y_reordered() +                             # 재정렬한 y축의 값 설정\n  labs(x = expression(\"단어 확률분포: \"~beta), y = NULL,\n       title = \"GS25 주제별 단어 확률 분포 (2022)\",\n       subtitle = \"주제별로 다른 단어들로 군집\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n\n\n2.0.7 관련보도 상위 주제어\n\n2.0.7.1 GS25(2021)\n\n\nCode\nGS25_2021_td_gamma <- GS25_2021_stm_fit %>% tidy(matrix = \"gamma\") \nGS25_2021_top_terms <- \nGS25_2021_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 5) %>% \n  select(topic, term) %>% \n  summarise(terms = str_flatten(term, collapse = \", \")) \n\nGS25_2021_gamma_terms <- \nGS25_2021_td_gamma %>% \n  group_by(topic) %>% \n  summarise(gamma = mean(gamma)) %>% \n  left_join(GS25_2021_top_terms, by = 'topic') %>% \n  left_join(GS25_2021_topic_name, by = 'topic')\n  \nGS25_2021_gamma_terms %>% \n  \n  ggplot(aes(x = gamma, y = reorder(name, gamma), fill = name)) +\n  geom_col(show.legend = F) +\n  geom_text(aes(label = round(gamma, 2)), # 소수점 2자리 \n            hjust = 1.15) +                # 라벨을 막대도표 안쪽으로 이동\n  geom_text(aes(label = terms), \n            hjust = -0.05) +              # 단어를 막대도표 바깥으로 이동\n  #scale_x_continuous(expand = c(0, 0),    # x축 막대 위치를 Y축쪽으로 조정\n  #                   limit = c(0, 1)) +   # x축 범위 설정\n  labs(x = expression(\"문서 확률분포\"~(gamma)), y = NULL,\n       title = \"GS25 관련보도 상위 주제어 (2021)\",\n       subtitle = \"주제별로 기여도가 높은 단어 중심\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n주류 판매가 주요 매출 제품으로 파악됨.\n페이 결제, 택배 선결제를 바탕으로 ’결제 방식’을 개선하였고, 배달 서비스를 시작하였으며, LG유플러스와 협약하여 AI, 빅데이터 솔루션을 도입하고 LG 유플러스 멤버십 대상 구독 서비스를 선보이기도 하였다. 즉, 2021년의 경우, GS25는 편의점의 기능을 개선하는데 초점을 둠.\n남성 혐오 논란이 브랜드에 막대한 부정적인 영향을 미쳤음을 확인할 있음.\n\n\n\n2.0.7.2 GS25(2022)\n\n\nCode\nGS25_2022_td_gamma <- GS25_2022_stm_fit %>% tidy(matrix = \"gamma\") \nGS25_2022_top_terms <- \nGS25_2022_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 5) %>% \n  select(topic, term) %>% \n  summarise(terms = str_flatten(term, collapse = \", \")) \n\nGS25_2022_gamma_terms <- \nGS25_2022_td_gamma %>% \n  group_by(topic) %>% \n  summarise(gamma = mean(gamma)) %>% \n  left_join(GS25_2022_top_terms, by = 'topic') %>% \n  left_join(GS25_2022_topic_name, by = 'topic')\n  \nGS25_2022_gamma_terms %>% \n  \n  ggplot(aes(x = gamma, y = reorder(name, gamma), fill = name)) +\n  geom_col(show.legend = F) +\n  geom_text(aes(label = round(gamma, 2)), # 소수점 2자리 \n            hjust = 1.15) +                # 라벨을 막대도표 안쪽으로 이동\n  geom_text(aes(label = terms), \n            hjust = -0.05) +              # 단어를 막대도표 바깥으로 이동\n  #scale_x_continuous(expand = c(0, 0),    # x축 막대 위치를 Y축쪽으로 조정\n  #                   limit = c(0, 1)) +   # x축 범위 설정\n  labs(x = expression(\"문서 확률분포\"~(gamma)), y = NULL,\n       title = \"GS25 관련보도 상위 주제어 (2022)\",\n       subtitle = \"주제별로 기여도가 높은 단어 중심\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n작년과 동일하게 주류판매에 대한 키워드 결집이 높고, 이전과 다르게 ‘소주’ 키워드가 증가함.\n세븐일레븐이 미니스톱을 인수한 내용이 많이 언급됨으로 보아 세븐일레븐의 몸집 증가가 기존에 자리잡고 있던 CU, GS25에 큰 영향을 미치는 것으로 보임.\n제품 다양화, 할인 이벤트 등을 시행함으로써 도시락 상품에 집중함.\n장기적인 관점에서, 로블록스(메타버스 플랫폼) 게임을 개발하여 MZ세대와 알파세대를 대상으로 미래 소비층을 확보하려고 함.\n\n\n\n\n2.0.8 결론\n\n2.0.8.1 평판 비교\n\n2021년에는 편의점 기능에 대한 개선에 초점을 맞추었다면 2022녀에는 회사 및 제품 브랜딩에 더 초점을 맞추는 모습.\n2021년에는 LG유플러스 협약을 맺어 AI, 빅데이터 기반 운영을 시도하였으며 결제 방식 다양화 및 편리화, 배송 서비스 운영 등 환경적인 변화에 빠르게 대응하려는 것을 알 수 있음.\n2022년에는 경쟁사의 인수 상황이 높게 언급되면서 편의점 경쟁이 치열해지고 있음을 암시. 동시에 원소주, 포켓몬과의 콜라보레이션으로 긍정적인 이슈를 얻고 있으며 도시락 상품 다양화로 GS25만의 특색을 만들어가려고 함을 알 수 있음.\n\n\n\n2.0.8.2 평판 전략 방향\n\nGS25는 기능적인 측면과 상품 브랜딩에 있어서는 명확한 컨셉과 개선의 모습을 보이고 있으나, 부정적인 기업 브랜딩에 대한 대응은 미약하게 나타나고 있음.\n이전 보고서 “언론보도 분석을 통한 편의점 평판 비교 분석”에 따르면 GS25가 ‘동네 주요 기점’ 역할로서 장애인 취업 지원, 미아 방지 캠페인, 소화기 제공 등 노력하는 모습들이 타 편의점과 큰 차이점을 보였었는데 그에 비해 평판에 효과적으로 활용되지 못했다고 판단됨. 긍정적인 기업 이미지를 형성하기 위해서는 앞의 내용을 효과적으로 활용할 필요가 있음.\n2022년이 되어 편의점들의 사업확장 및 기업 인수를 통해 경쟁이 더 심화되리라 보고 있는데, 이 과정에서 GS25가 편의점 트렌드에 부합하게 평판관리를 하고 있는지도 살펴볼 필요가 있음."
  },
  {
    "objectID": "9th_data.html",
    "href": "9th_data.html",
    "title": "3  언론보도 분석을 통한 편의점의 연도별 이슈 및 트렌드 비교분석",
    "section": "",
    "text": "3.0.2 자료 수집\n\n3.0.2.1 패키지 설치\n\n\nCode\npackage_list <- c(\"tidyverse\", \"tidytext\", \"readxl\", \"kableExtra\", \n                  \"multilinguer\", \"RcppMeCab\", \"KoNLP\", \"lubridate\", \n                  \"tidylo\", \"stm\", \"reshape2\", \"dplyr\", \"ggplot2\", \n                  \"stringr\", \"rvest\", \"wordcloud\", \"tm\", \"VennDiagram\", \"gt\")\n \n#package_list_installed <- package_list %in% installed.packages()[,\"Package\"]\n# new_pkg <- package_list[!package_list_installed]\n# if(length(new_pkg)) install.packages(new_pkg)\n\nlapply(package_list, require, character.only = TRUE)\n\n\n\n\n3.0.2.2 데이터셋 수집\n\n\nCode\nstore_2021_df <- readxl::read_excel(\"store_21_data.xlsx\") %>% \n  select(제목, 본문)\n\nstore_2022_df <- readxl::read_excel(\"store_22_data.xlsx\") %>% \n  select(제목, 본문)\n\n\n\n\n\n3.0.3 자료분석-총빈도\n\n3.0.3.1 편의점 (2021. 01. 01. ~ 2021. 10. 31. / 약 10개월)\n\n\nCode\nstore_2021_df <- store_2021_df %>% \n  distinct(제목, .keep_all = T) %>% \n  mutate(ID = factor(row_number())) %>% \n  mutate(label = \"0\") %>%\n  unite(제목, 본문, col = \"text\", sep = \" \") %>% \n  mutate(text = str_squish(text))\n\nstore_2021_tk <- store_2021_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F) %>%\n  count(word, sort = T)\n\nstore_2021_tk <- \nstore_2021_tk %>% \n  filter(!word %in% c(\"기자\", \"편의점\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\")) %>%\n  filter(str_length(word) > 1) %>%\n  slice_max(n, n = 15) %>% \n  mutate(word = reorder(word, n))\n\nstore_2021_tk %>%\n  ggplot(aes(word, n)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"편의점 총빈도 (2021)\")\n\n\n\n\n\n\n\n3.0.3.2 편의점 (2022. 01. 01. ~ 2022. 10. 31. / 약 10개월)\n\n\nCode\nstore_2022_df <- store_2022_df %>% \n  distinct(제목, .keep_all = T) %>% \n  mutate(ID = factor(row_number())) %>% \n  mutate(label = \"0\") %>%\n  unite(제목, 본문, col = \"text\", sep = \" \") %>% \n  mutate(text = str_squish(text))\n\nstore_2022_tk <- store_2022_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F) %>%\n  count(word, sort = T)\n\nstore_2022_tk <- \nstore_2022_tk %>% \n  filter(!word %in% c(\"기자\", \"편의점\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\")) %>%\n  filter(str_length(word) > 1) %>%\n  slice_max(n, n = 15) %>% \n  mutate(word = reorder(word, n))\n\nstore_2022_tk %>%\n  ggplot(aes(word, n)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"편의점 총빈도 (2022)\")\n\n\n\n\n\n\n\n3.0.3.3 분석\n\n전반적으로 ‘출시’, ‘판매’, ‘리테일’ 등 편의점의 기본적인 기능과 관련된 단어들이 많이 언급되고 있음.\n2021년에는 ’맥주’가, 2022년에는 ’키트’가 주요 상품으로 보임. 여기서 ’키트’는 코로나19 단어와 함께 있는 것으로 보아 ’코로나 자가진단키트’를 의미함.\n2021년 총빈도를 살펴보면 CU, GS25, 세븐일레븐 순으로 편의점 브랜드 언급이 많았음. 그리고 CU의 경우, 2021년과 2022년에 모두 언급된 유일한 브랜드임.\n\n\n\n\n3.0.4 자료분석-상대빈도\n\n\nCode\nweighted_log_odds_df <-\n  bind_rows(store_2021_tk, store_2022_tk, .id = \"party\") %>% \n  bind_log_odds(set = party,\n                feature = word, \n                n = n) %>% \n  arrange(-log_odds_weighted)\n\n\n\n\nCode\nlibrary(gt)\nlibrary(dplyr)\n\nstore_2021.2022_df <- bind_cols(\n  weighted_log_odds_df %>%   \n  group_by(party = ifelse(party == 1, \"store(2021)\", \"store(2022)\")) %>% \n  arrange(party) %>% \n  select(-party) %>%\n  head(15),\n  \n  weighted_log_odds_df %>%   \n  group_by(party = ifelse(party == 1, \"store(2021)\", \"store(2022)\")) %>% \n  arrange(desc(party)) %>% \n  select(-party) %>%\n  head(15) \n  ) \n\nstore_2021.2022_df <- store_2021.2022_df[-c(1,5)]\n\nstore_2021.2022_df %>%\n  gt() %>% tab_header(\n  \"상대적으로 많이 사용한 단어\"\n  ) %>% tab_spanner(\n    label = \"store (2021)\",\n    columns = 1:3\n  ) %>% tab_spanner(\n    label = \"store (2022)\",\n    columns = 4:6\n  ) %>% cols_label(\n    word...2 = \"명사\",\n    n...3 = \"빈도\",\n    log_odds_weighted...4 = \"가중상대빈도\",\n    word...6 = \"명사\",\n    n...7 = \"빈도\",\n    log_odds_weighted...8 = \"가중상대빈도\"\n  ) %>% fmt_number(\n    columns = starts_with(\"log\"), \n    decimals = 2\n  )\n\n\n\n\n\n\n  \n    \n      상대적으로 많이 사용한 단어\n    \n    \n  \n  \n    \n      \n        store (2021)\n      \n      \n        store (2022)\n      \n    \n    \n      명사\n      빈도\n      가중상대빈도\n      명사\n      빈도\n      가중상대빈도\n    \n  \n  \n    맥주\n2437\n35.14\n가격\n3058\n40.40\n    gs\n2397\n34.83\n키트\n2479\n36.06\n    지난해\n2169\n33.02\n검사\n2159\n33.50\n    매출\n2119\n32.62\n제품\n2025\n32.38\n    세븐일레븐\n2018\n31.78\n들이\n1934\n31.60\n    리테일\n2814\n2.54\n판매\n3459\n2.53\n    서비스\n2680\n2.08\n출시\n3360\n−0.08\n    코로나19\n2410\n1.58\n상품\n2473\n−0.28\n    운영\n2408\n0.91\n경찰\n2192\n−0.56\n    서울\n2526\n0.81\ncu\n3041\n−0.59\n    cu\n3277\n0.58\n서울\n2286\n−0.82\n    경찰\n2376\n0.55\n운영\n2157\n−0.92\n    상품\n2615\n0.27\n코로나19\n2036\n−1.60\n    출시\n3497\n0.08\n서비스\n2188\n−2.11\n    판매\n3018\n−2.53\n리테일\n2222\n−2.58\n  \n  \n  \n\n\n\n\n\n2021년에는 ‘배달’, ‘온라인’ 등 비대면 서비스와 관련된 단어 빈도가 상대적으로 높게 나타남.\n2021년에는 ’맥주’가, 2022년에는 ’소주’가 많이 언급되면서 편의점에서의 주류 판매가 주요 트렌드임을 알 수 있음.\n\n\n\n3.0.5 감정분석\n\n3.0.5.1 사전 데이터 프레임 만들기\n\n\nCode\n# pkg_v <- c(\"tidyverse\", \"tidytext\", \"epubr\", \"RcppMeCab\", \"KoNLP\" )\n# lapply(pkg_v, require, ch = T)\n\n# url_v <- \"https://github.com/park1200656/KnuSentiLex/archive/refs/heads/master.zip\"\n# dest_v <- \"data/knusenti.zip\"\n# download.file(url = url_v, destfile = dest_v, mode = \"wb\")\n\n# unzip(\"knusenti.zip\", exdir=outPath)\n\n\n\n\nCode\nsenti_name_v <- list.files(\"data/knusenti/KnuSentiLex-master/.\")[9]\nsenti_dic_df <- read_tsv(str_c(\"data/knusenti/KnuSentiLex-master/\", senti_name_v), col_names = F)\nsenti_dic_df <- senti_dic_df %>% rename(word = X1, sScore = X2)\nknu_dic_df <- senti_dic_df %>% \n  filter(!is.na(sScore))\n\n\n\n\n3.0.5.2 편의점(2021)\n\n\nCode\nstore_2021_senti_df <- store_2021_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  count(word, sScore, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  mutate(word = reorder(word, n)) %>% \n  slice_head(n = 20)\n\nstore_2021_senti_df %>% \n  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +\n    labs(title = \"편의점 감정빈도 분석 (2021)\")\n\n\n\n\n\n\n\nCode\nstore_2021_df %>% \n  unnest_tokens(word, text) %>% \n  left_join(knu_dic_df) %>% \n  mutate(sScore = ifelse(sScore >= 1, \"긍정\",\n                         ifelse(sScore <= -1, \"부정\", \"중립\"))) %>% \n  count(sScore)\n\n\n# A tibble: 4 × 2\n  sScore       n\n  <chr>    <int>\n1 긍정     14044\n2 부정      7482\n3 중립       530\n4 <NA>   1074071\n\n\nCode\nstore_2021_df %>%   \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>%\n  mutate(label = ifelse(sScore > 0, \"1\", ifelse(sScore < 0, \"0\", \"2\"))) %>%\n  filter(label != \"중립\") %>%\n  count(word, emotion, label, sort = T) %>%\n  filter(str_length(word) > 1) %>%\n  group_by(label = ifelse(label > 0, \"긍정\", \"부정\")) %>%\n  slice_head(n = 15) %>%\n  ggplot(aes(x = n,\n             y = reorder(word, n), fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\") +\n  labs(title = \"편의점 긍정어 부정어 (2021)\")\n\n\n\n\n\n\n편의점(2021) 긍정 이미지 : ‘할인’, ‘인기’, ‘혜택’, ‘이벤트’. ‘안전’, ‘사랑’, ‘혁신’\n편의점(2021) 부정 이미지 : ‘폭행’, ’범죄’의 경우 편의점과 직접적연 연관이라기 보다는 관련 사건들을 설명하는데 사용됨. ’부담’의 경우 부정적인 단어를 활용하여 마케팅을 하면서 나타남. ’혐오’는 GS25의 홍보포스터가 남성 혐오 논란을 일으키면서 높은 비중을 차지함.\n\n\n\n3.0.5.3 편의점(2022)\n\n\nCode\nstore_2022_senti_df <- store_2022_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  count(word, sScore, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  mutate(word = reorder(word, n)) %>% \n  slice_head(n = 20)\n\nstore_2022_senti_df %>% \n  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +\n    labs(title = \"편의점 감정빈도 분석 (2022)\")\n\n\n\n\n\n\n\nCode\nstore_2022_df %>% \n  unnest_tokens(word, text) %>% \n  left_join(knu_dic_df) %>% \n  mutate(sScore = ifelse(sScore >= 1, \"긍정\",\n                         ifelse(sScore <= -1, \"부정\", \"중립\"))) %>% \n  count(sScore)\n\n\n# A tibble: 4 × 2\n  sScore       n\n  <chr>    <int>\n1 긍정     12197\n2 부정      7269\n3 중립       573\n4 <NA>   1045330\n\n\nCode\nstore_2022_df %>%   \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>%\n  mutate(label = ifelse(sScore > 0, \"1\", ifelse(sScore < 0, \"0\", \"2\"))) %>%\n  filter(label != \"중립\") %>%\n  count(word, emotion, label, sort = T) %>%\n  filter(str_length(word) > 1) %>%\n  group_by(label = ifelse(label > 0, \"긍정\", \"부정\")) %>%\n  slice_head(n = 15) %>%\n  ggplot(aes(x = n,\n             y = reorder(word, n), fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\") +\n  labs(title = \"편의점 긍정어 부정어 (2022)\")\n\n\n\n\n\n\n편의점(2022) 긍정 이미지 : ‘인기’, ‘할인’, ‘이벤트’, ‘이벤트’. ‘안정’, ‘혁신’, ‘성공’\n편의점(2022) 부정 이미지 : ‘부담’의 경우 부정적인 단어를 활용하여 마케팅을 하면서 나타남. ’폭행’, ’범죄’의 경우 편의점과 직접적연 연관이라기 보다는 관련 사건들을 설명하는데 사용됨.’장애인’의 경우, 장애인 직업 훈련과 관련하여 일자리 창출 측면에서 긍정적인 의미와 장애인 편의시설이 갖추어질 필요가 있다는 장애인 이동권 측면에서 부정적인 의미를 함께 내포하고 있음.\n\n\n\n\n3.0.6 토픽모델링\n\n3.0.6.1 편의점(2021)\n\n\nCode\nstore_2021_topic_tk <- store_2021_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F)\n\nstore_2021_topic_tk <- \nstore_2021_topic_tk %>% \n  filter(!word %in% c(\"기자\", \"편의점\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nstore_2021_combined_df <-\n  store_2021_topic_tk %>%\n  group_by(ID) %>%\n  summarise(text2 = str_flatten(word, \" \")) %>%\n  ungroup() %>% \n  inner_join(store_2021_df, by = \"ID\")\n\nlibrary(stm)\nlibrary(tm)\n\nprocessed <- \n  store_2021_df %>% textProcessor(\n    documents = store_2021_combined_df$text2,\n    metadata = .,\n    wordLengths = c(2, Inf)\n    )\n\n\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n\n\nCode\nout <-\n  prepDocuments(processed$documents,\n                processed$vocab,\n                processed$meta, \n                lower.thresh = 0)\ndocs <- out$documents\nvocab <- out$vocab\nmeta <- out$meta\ntopicN <- c(3, 10)\n#storage <- searchK(out$documents, out$vocab, K = topicN)\n\nstore_2021_stm_fit <-\n  stm(\n    documents = docs,\n    vocab = vocab,\n    K = 6,\n    data = meta,\n    max.em.its = 75,\n    init.type = \"Spectral\",\n    seed = 25,\n    verbose = F\n  )\n\n#labelTopics(GS25_stm_fit)\n\nstore_2021_topic_name <- tibble(topic = 1:6,\n                     name = c(\"1. 코로나 상황\",\n                              \"2. 제품 출시\",\n                              \"3. 범죄 및 논란\",\n                              \"4. 결제 방식\",\n                              \"5. 유통\",\n                              \"6. 점포 운영\"))\n\nstore_2021_td_beta <- store_2021_stm_fit %>% tidy(matrix = 'beta') \nstore_2021_topic_name <- store_2021_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 7) %>% \n  left_join(store_2021_topic_name, by = \"topic\")\n\nstore_2021_topic_name %>% \n  ggplot(aes(x = beta, \n             y = reorder_within(term, beta, name),  # 각 주제별로 재정렬\n             fill = name)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~name, scales = \"free\") +\n  scale_y_reordered() +                             # 재정렬한 y축의 값 설정\n  labs(x = expression(\"단어 확률분포: \"~beta), y = NULL,\n       title = \"편의점 주제별 단어 확률 분포 (2021)\",\n       subtitle = \"주제별로 다른 단어들로 군집\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n\n3.0.6.2 편의점(2022)\n\n\nCode\nstore_2022_topic_tk <- store_2022_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F)\n\nstore_2022_topic_tk <- \nstore_2022_topic_tk %>% \n  filter(!word %in% c(\"기자\", \"편의점\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nstore_2022_combined_df <-\n  store_2022_topic_tk %>%\n  group_by(ID) %>%\n  summarise(text2 = str_flatten(word, \" \")) %>%\n  ungroup() %>% \n  inner_join(store_2021_df, by = \"ID\")\n\nlibrary(stm)\nlibrary(tm)\n\nprocessed <- \n  store_2022_df %>% textProcessor(\n    documents = store_2022_combined_df$text2,\n    metadata = .,\n    wordLengths = c(2, Inf)\n    )\n\n\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n\n\nCode\nout <-\n  prepDocuments(processed$documents,\n                processed$vocab,\n                processed$meta, \n                lower.thresh = 0)\ndocs <- out$documents\nvocab <- out$vocab\nmeta <- out$meta\ntopicN <- c(3, 10)\n#storage <- searchK(out$documents, out$vocab, K = topicN)\n\nstore_2022_stm_fit <-\n  stm(\n    documents = docs,\n    vocab = vocab,\n    K = 6,\n    data = meta,\n    max.em.its = 75,\n    init.type = \"Spectral\",\n    seed = 25,\n    verbose = F\n  )\n\n#labelTopics(GS25_stm_fit)\n\nstore_2022_topic_name <- tibble(topic = 1:6,\n                     name = c(\"1. 범죄 및 논란\",\n                              \"2. 점포 운영\",\n                              \"3. 제품 출시\",\n                              \"4. 프로모션\",\n                              \"5. 코로나 상황\",\n                              \"6. 유통\"))\n\nstore_2022_td_beta <- store_2022_stm_fit %>% tidy(matrix = 'beta') \nstore_2022_topic_name <- store_2022_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 7) %>% \n  left_join(store_2022_topic_name, by = \"topic\")\n\nstore_2022_topic_name %>% \n  ggplot(aes(x = beta, \n             y = reorder_within(term, beta, name),  # 각 주제별로 재정렬\n             fill = name)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~name, scales = \"free\") +\n  scale_y_reordered() +                             # 재정렬한 y축의 값 설정\n  labs(x = expression(\"단어 확률분포: \"~beta), y = NULL,\n       title = \"편의점 주제별 단어 확률 분포 (2022)\",\n       subtitle = \"주제별로 다른 단어들로 군집\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n\n\n3.0.7 관련보도 상위 주제어\n\n3.0.7.1 편의점(2021)\n\n\nCode\nstore_2021_td_gamma <- store_2021_stm_fit %>% tidy(matrix = \"gamma\") \nstore_2021_top_terms <- \nstore_2021_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 5) %>% \n  select(topic, term) %>% \n  summarise(terms = str_flatten(term, collapse = \", \")) \n\nstore_2021_gamma_terms <- \nstore_2021_td_gamma %>% \n  group_by(topic) %>% \n  summarise(gamma = mean(gamma)) %>% \n  left_join(store_2021_top_terms, by = 'topic') %>% \n  left_join(store_2021_topic_name, by = 'topic')\n  \nstore_2021_gamma_terms %>% \n  \n  ggplot(aes(x = gamma, y = reorder(name, gamma), fill = name)) +\n  geom_col(show.legend = F) +\n  geom_text(aes(label = round(gamma, 2)), # 소수점 2자리 \n            hjust = 1.15) +                # 라벨을 막대도표 안쪽으로 이동\n  geom_text(aes(label = terms), \n            hjust = -0.05) +              # 단어를 막대도표 바깥으로 이동\n  #scale_x_continuous(expand = c(0, 0),    # x축 막대 위치를 Y축쪽으로 조정\n  #                   limit = c(0, 1)) +   # x축 범위 설정\n  labs(x = expression(\"문서 확률분포\"~(gamma)), y = NULL,\n       title = \"편의점 관련보도 상위 주제어 (2021)\",\n       subtitle = \"주제별로 기여도가 높은 단어 중심\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n‘맥주’ 관련 상품 판매 및 출시가 주요 트렌드임을 알 수 있음.\n코로나 상황으로 인하여 사회적 거리두기, 운영 시간 등 고려해야 할 점들이 있었음. 더불어 코로나 상황으로 인하여 ’배달’과 같은 비대면 서비스가 활성화됨.\n’지역’기반의 운영이 점포 운영에 있어 주요 키워드로 나타남.\n일상생활 반경 내 편의점의 갯수가 증가함에 따라 범죄 및 치안과 관련하여 ’편의점’에 대한 언급이 많이 나타남.\n‘카드’, ‘포인트’ 등 결제할 수 있는 방식이 다양해졌으며, ‘택배’ 등과 같은 부수적인 서비스도 편의점 내에서 이용가능하게 됨.\n\n\n\n3.0.7.2 편의점(2022)\n\n\nCode\nstore_2022_td_gamma <- store_2022_stm_fit %>% tidy(matrix = \"gamma\") \nstore_2022_top_terms <- \nstore_2022_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 5) %>% \n  select(topic, term) %>% \n  summarise(terms = str_flatten(term, collapse = \", \")) \n\nstore_2022_gamma_terms <- \nstore_2022_td_gamma %>% \n  group_by(topic) %>% \n  summarise(gamma = mean(gamma)) %>% \n  left_join(store_2022_top_terms, by = 'topic') %>% \n  left_join(store_2022_topic_name, by = 'topic')\n  \nstore_2022_gamma_terms %>% \n  \n  ggplot(aes(x = gamma, y = reorder(name, gamma), fill = name)) +\n  geom_col(show.legend = F) +\n  geom_text(aes(label = round(gamma, 2)), # 소수점 2자리 \n            hjust = 1.15) +                # 라벨을 막대도표 안쪽으로 이동\n  geom_text(aes(label = terms), \n            hjust = -0.05) +              # 단어를 막대도표 바깥으로 이동\n  #scale_x_continuous(expand = c(0, 0),    # x축 막대 위치를 Y축쪽으로 조정\n  #                   limit = c(0, 1)) +   # x축 범위 설정\n  labs(x = expression(\"문서 확률분포\"~(gamma)), y = NULL,\n       title = \"편의점 관련보도 상위 주제어 (2022)\",\n       subtitle = \"주제별로 기여도가 높은 단어 중심\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n‘맥주’ 관련 상품 판매 및 출시가 주요 트렌드임을 알 수 있음.\n최근 물가 상승으로 인하여 가격이 인상되는 제품들이 있는데, 이와 대비되게 가격 할인 이벤트를 함께 진행함. 그리고 ’포켓몬’과 같이 특정 캐릭터 등과 콜라보레이션을 하여 제품 및 이벤트를 진행함.\n편의점이 코로나 자가진단키트 주요 구매처 역할을 하고 있음.\n일상생활 반경 내 편의점의 갯수가 증가함에 따라 범죄 및 치안과 관련하여 ‘편의점’에 대한 언급이 많이 나타남. 편의점에 기본적인 판매 기능뿐만 아니라 ’청소년’, ‘안전’ 등 동네 지킴이 역할을 하는 모습을 보이고 있음.\n\n\n\n\n3.0.8 결론\n\n3.0.8.1 이슈 및 트렌드 비교 분석\n\n2021년, 2022년 모두 ‘맥주’, ‘소주’ 등 주류 상품 출시 및 판매에 집중하는 모습을 보이고 있고, 이에 대해 소비자로 하여금 긍정적인 반응을 얻고 있음.\n2021년 ‘지역’ 기반의 점포 운영이 키워드로 등장하였는데, 2022년 편의점에서 ‘청소년’, ‘안전’ 등 동네 치안과 관련하여 여러 캠페인을 실시하는 것으로 보아 ’동네 거점 기능’이 더 고도화되었음을 알 수 있음.\n2021년에는 ‘결제 서비스’, ‘배달 서비스’ 등 편의점에 기본적인 기능에 집중을 하였다면, 2022년에는 ‘포켓몬’ 등 타 브랜드와의 콜라보레이션을 통해 프로모션을 펼치고 있음.\n\n\n\n3.0.8.2 앞으로의 편의점 방향성\n\n동네 거점 기능 : 커머스 산업군에 있어 ’편의점’이 가지고 있는 주요 특징은 동네 곳곳에 점포가 위치하고 있다는 것임. 이 특징을 극대화하기 위해 ’동네 거점 기능’이 극대화되고 있으며 이러한 흐름에 맞추어 캠페인 혹은 편의점 기능을 개선할 필요가 있음.\n서비스 및 제품의 차별화 : 타 브랜드와의 콜라보를 통해 새로운 상품을 출시하거나 좀 더 편리한 서비스를 제공하고 있는 추세. 단순 유통 중심의 커머스 개념에서 벗어나 브랜드만의 특색을 갖출 필요가 있음."
  }
]